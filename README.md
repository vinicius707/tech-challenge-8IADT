# Tech Challenge - Fase 1

## Sistema Inteligente de Suporte ao DiagnÃ³stico MÃ©dico

Este projeto implementa modelos de machine learning para **classificaÃ§Ã£o de exames mÃ©dicos**, utilizando dados estruturados e imagens para auxiliar profissionais de saÃºde na tomada de decisÃ£o clÃ­nica.

> âš ï¸ **IMPORTANTE**: Este sistema nÃ£o substitui o mÃ©dico. Ele atua como ferramenta de apoio e triagem. A decisÃ£o final sempre deve ser do profissional mÃ©dico qualificado.

---

## ğŸ“‘ Ãndice

1. [Problema Abordado](#-problema-abordado)
2. [Datasets Utilizados](#-datasets-utilizados)
3. [Estrutura do Projeto](#-estrutura-do-projeto)
4. [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#-instalaÃ§Ã£o-e-configuraÃ§Ã£o)
5. [ğŸ“š Guia Passo a Passo Completo](#-guia-passo-a-passo-completo)
   - [Notebook 01: ExploraÃ§Ã£o de Dados Tabulares (CÃ¢ncer de Mama)](#notebook-01-exploraÃ§Ã£o-de-dados-tabulares-cÃ¢ncer-de-mama)
   - [Notebook 02: Modelagem de Dados Tabulares (CÃ¢ncer de Mama)](#notebook-02-modelagem-de-dados-tabulares-cÃ¢ncer-de-mama)
   - [Notebook 03: ExploraÃ§Ã£o de Imagens de Pneumonia](#notebook-03-exploraÃ§Ã£o-de-imagens-de-pneumonia)
   - [Notebook 04: Modelagem CNN para Pneumonia](#notebook-04-modelagem-cnn-para-pneumonia)
   - [Notebook 05: ExploraÃ§Ã£o de Mamografias](#notebook-05-exploraÃ§Ã£o-de-mamografias)
   - [Notebook 06: Modelagem CNN para CÃ¢ncer de Mama](#notebook-06-modelagem-cnn-para-cÃ¢ncer-de-mama)
   - [Notebook 07: ExploraÃ§Ã£o de Diabetes](#notebook-07-exploraÃ§Ã£o-de-diabetes)
   - [Notebook 08: Modelagem de Diabetes](#notebook-08-modelagem-de-diabetes)
6. [ğŸ”¬ Detalhes TÃ©cnicos](#-detalhes-tÃ©cnicos)
7. [ğŸ“ˆ Resultados Esperados](#-resultados-esperados)
8. [ğŸ” Interpretabilidade](#-interpretabilidade)
9. [âš ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes](#ï¸-limitaÃ§Ãµes-e-consideraÃ§Ãµes)
10. [ğŸ³ Docker](#-docker)
11. [ğŸ“š DocumentaÃ§Ã£o Adicional](#-documentaÃ§Ã£o-adicional)

---

## ğŸ“Œ Problema Abordado

Este projeto aborda quatro tipos de classificaÃ§Ã£o mÃ©dica:

### 1. ClassificaÃ§Ã£o de CÃ¢ncer de Mama (Dados Tabulares)

ClassificaÃ§Ã£o binÃ¡ria para diagnÃ³stico de **cÃ¢ncer de mama** em duas categorias:

- **B (Benigno)**: Tumor benigno
- **M (Maligno)**: Tumor maligno

O modelo utiliza caracterÃ­sticas clÃ­nicas numÃ©ricas obtidas de exames mÃ©dicos (raio, textura, perÃ­metro, Ã¡rea, suavidade, compactaÃ§Ã£o, concavidade, etc.) para fazer prediÃ§Ãµes.

### 2. ClassificaÃ§Ã£o de Diabetes (Dados Tabulares)

ClassificaÃ§Ã£o binÃ¡ria para diagnÃ³stico de **diabetes** em duas categorias:

- **0 (NÃ£o DiabÃ©tico)**: Paciente sem diabetes
- **1 (DiabÃ©tico)**: Paciente com diabetes

O modelo utiliza 8 caracterÃ­sticas clÃ­nicas (Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age) para fazer prediÃ§Ãµes.

### 3. ClassificaÃ§Ã£o de Imagens MÃ©dicas (CNNs)

#### 3.1 Pneumonia em Raio-X

ClassificaÃ§Ã£o binÃ¡ria de imagens de raio-X de tÃ³rax:

- **Normal**: Sem sinais de pneumonia
- **Pneumonia**: Com sinais de pneumonia

#### 3.2 CÃ¢ncer de Mama em Mamografias

ClassificaÃ§Ã£o binÃ¡ria de imagens de mamografia:

- **Benigno**: LesÃµes benignas
- **Maligno**: LesÃµes malignas (cÃ¢ncer)

---

## ğŸ§ª Datasets Utilizados

### Dados Tabulares

#### CÃ¢ncer de Mama

- **Dataset**: Wisconsin Breast Cancer Dataset
- **Fonte**: UCI Machine Learning Repository
- **Tamanho**: 569 amostras
- **Features**: 30 caracterÃ­sticas numÃ©ricas
- **DistribuiÃ§Ã£o**: ~62% benigno, ~38% maligno
- **LocalizaÃ§Ã£o**: `data/tabular/breast-cancer.csv`

#### Diabetes

- **Dataset**: Diabetes Data Set
- **Fonte**: Kaggle (mathchi/diabetes-data-set)
- **Tamanho**: 768 amostras
- **Features**: 8 caracterÃ­sticas clÃ­nicas (Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age)
- **DistribuiÃ§Ã£o**: ~65% nÃ£o diabÃ©tico, ~35% diabÃ©tico
- **LocalizaÃ§Ã£o**: `data/tabular/diabetes.csv`

### Dados de Imagens

#### Pneumonia em Raio-X

- **Dataset**: Chest X-Ray Images (Pneumonia)
- **Fonte**: Kaggle (paultimothymooney/chest-xray-pneumonia)
- **Tipo**: Imagens de raio-X de tÃ³rax
- **Classes**: Normal, Pneumonia
- **Download**: AutomÃ¡tico via kagglehub

#### CÃ¢ncer de Mama (CBIS-DDSM)

- **Dataset**: CBIS-DDSM (Curated Breast Imaging Subset of DDSM)
- **Fonte**: Kaggle (awsaf49/cbis-ddsm-breast-cancer-image-dataset)
- **Tipo**: Imagens de mamografia
- **Classes**: Benigno, Maligno
- **Download**: AutomÃ¡tico via kagglehub

### CaracterÃ­sticas do Dataset Tabular

O dataset contÃ©m medidas computadas a partir de imagens digitalizadas de aspirados por agulha fina (FNA) de massas mamÃ¡rias. As features descrevem caracterÃ­sticas do nÃºcleo celular, incluindo:

- **Raio**: MÃ©dia das distÃ¢ncias do centro aos pontos do perÃ­metro
- **Textura**: Desvio padrÃ£o dos valores de escala de cinza
- **PerÃ­metro**: PerÃ­metro do nÃºcleo
- **Ãrea**: Ãrea do nÃºcleo
- **Suavidade**: VariaÃ§Ã£o local nos comprimentos dos raios
- **CompactaÃ§Ã£o**: PerÃ­metroÂ² / Ã¡rea - 1.0
- **Concavidade**: Severidade das porÃ§Ãµes cÃ´ncavas do contorno
- **Pontos cÃ´ncavos**: NÃºmero de porÃ§Ãµes cÃ´ncavas do contorno
- **Simetria**: Medida de simetria
- **DimensÃ£o fractal**: AproximaÃ§Ã£o "coastline" - 1

Cada feature possui trÃªs versÃµes: `_mean` (mÃ©dia), `_se` (erro padrÃ£o), `_worst` (pior valor).

---

## ğŸ— Estrutura do Projeto

```
tech-challenge-8IADT/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tabular/
â”‚   â”‚   â””â”€â”€ breast-cancer.csv          # Dataset tabular
â”‚   â””â”€â”€ images/
â”‚       â”œâ”€â”€ pneumonia/                  # Dataset de pneumonia (baixado)
â”‚       â””â”€â”€ breast_cancer/             # Dataset de cÃ¢ncer de mama (baixado)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_tabular_exploracao.ipynb           # EDA dados tabulares (cÃ¢ncer de mama)
â”‚   â”œâ”€â”€ 02_tabular_modelagem.ipynb            # Modelagem dados tabulares (cÃ¢ncer de mama)
â”‚   â”œâ”€â”€ 03_vision_pneumonia_exploracao.ipynb  # EDA pneumonia
â”‚   â”œâ”€â”€ 04_vision_pneumonia_modelagem.ipynb   # CNN pneumonia
â”‚   â”œâ”€â”€ 05_vision_breast_exploracao.ipynb     # EDA cÃ¢ncer de mama (imagens)
â”‚   â”œâ”€â”€ 06_vision_breast_modelagem.ipynb      # CNN cÃ¢ncer de mama (imagens)
â”‚   â”œâ”€â”€ 07_diabetes_exploracao.ipynb          # EDA diabetes
â”‚   â””â”€â”€ 08_diabetes_modelagem.ipynb           # Modelagem diabetes
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tabular/
â”‚   â”‚   â”œâ”€â”€ processing.py              # PrÃ©-processamento tabular
â”‚   â”‚   â””â”€â”€ evaluate.py                # AvaliaÃ§Ã£o tabular
â”‚   â””â”€â”€ vision/
â”‚       â”œâ”€â”€ data_loader.py             # Carregamento de imagens
â”‚       â”œâ”€â”€ preprocessing.py           # PrÃ©-processamento de imagens
â”‚       â”œâ”€â”€ models.py                  # Arquiteturas CNN
â”‚       â””â”€â”€ evaluation.py              # AvaliaÃ§Ã£o e Grad-CAM
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ maternal_risk_model.pkl       # Modelo tabular (cÃ¢ncer de mama)
â”‚   â”œâ”€â”€ diabetes_model.pkl            # Modelo tabular (diabetes)
â”‚   â”œâ”€â”€ pneumonia_cnn_model.h5        # CNN pneumonia
â”‚   â””â”€â”€ breast_cancer_cnn_model.h5    # CNN cÃ¢ncer de mama
â”œâ”€â”€ config.yaml                        # ConfiguraÃ§Ãµes
â”œâ”€â”€ requirements.txt                   # DependÃªncias
â”œâ”€â”€ Dockerfile                         # ContainerizaÃ§Ã£o
â”œâ”€â”€ README.md                          # Este arquivo
â”œâ”€â”€ relatorio_tecnico.md               # RelatÃ³rio tÃ©cnico completo
```

---

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- Jupyter Notebook ou JupyterLab (para executar os notebooks)

### Passo 1: Clonar o RepositÃ³rio

```bash
git clone <url-do-repositorio>
cd tech-challenge-8IADT
```

### Passo 2: Instalar DependÃªncias

```bash
pip3 install -r requirements.txt
```

**Nota**: Se vocÃª receber um erro "command not found: pip", use `pip3` em vez de `pip`. No macOS, o comando geralmente Ã© `pip3`.

**Principais dependÃªncias**:

- `pandas`: ManipulaÃ§Ã£o de dados
- `numpy`: ComputaÃ§Ã£o numÃ©rica
- `scikit-learn`: Machine learning
- `tensorflow`: Deep learning e CNNs
- `matplotlib` e `seaborn`: VisualizaÃ§Ã£o
- `shap`: Interpretabilidade de modelos
- `kagglehub`: Download de datasets do Kaggle
- `pillow`, `scikit-image`: Processamento de imagens
- `jupyter`: Notebooks interativos

### Passo 3: Verificar Datasets

- **Dados Tabulares**: Certifique-se de que os arquivos estÃ£o presentes:
  - `data/tabular/breast-cancer.csv` (cÃ¢ncer de mama)
  - `data/tabular/diabetes.csv` (diabetes)
- **Dados de Imagens**: Os datasets serÃ£o baixados automaticamente ao executar os notebooks de exploraÃ§Ã£o (03 e 05)

### Passo 4: Iniciar Jupyter

```bash
jupyter notebook
```

Ou, se preferir JupyterLab:

```bash
jupyter lab
```

### Passo 5: Instalar DependÃªncias de Desenvolvimento (Opcional)

Para executar os testes do projeto:

```bash
pip3 install -r requirements-dev.txt
```

**Nota**: Se vocÃª receber um erro "command not found: pip", use `pip3` em vez de `pip`.

---

## ğŸ§ª Executando Testes

O projeto inclui uma suÃ­te completa de testes seguindo as melhores prÃ¡ticas de mercado.

### Executar Todos os Testes

```bash
pytest
```

### Executar Testes com Cobertura

```bash
pytest --cov=src --cov-report=html
```

Isso gerarÃ¡ um relatÃ³rio HTML em `htmlcov/index.html` mostrando a cobertura de cÃ³digo.

### Executar Apenas Testes UnitÃ¡rios

```bash
pytest tests/unit -m unit
```

### Executar Apenas Testes de IntegraÃ§Ã£o

```bash
pytest tests/integration -m integration
```

### Executar Testes EspecÃ­ficos

```bash
# Testar um mÃ³dulo especÃ­fico
pytest tests/unit/test_tabular_processing.py

# Testar uma classe especÃ­fica
pytest tests/unit/test_tabular_processing.py::TestSplitData

# Testar uma funÃ§Ã£o especÃ­fica
pytest tests/unit/test_tabular_processing.py::TestSplitData::test_split_data_basic
```

### Ver Cobertura de CÃ³digo

```bash
# Cobertura no terminal
pytest --cov=src --cov-report=term-missing

# Cobertura em HTML (abre no navegador)
pytest --cov=src --cov-report=html && open htmlcov/index.html
```

### Estrutura de Testes

```
tests/
â”œâ”€â”€ conftest.py              # Fixtures compartilhadas
â”œâ”€â”€ unit/                     # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ test_tabular_processing.py
â”‚   â”œâ”€â”€ test_tabular_evaluate.py
â”‚   â”œâ”€â”€ test_vision_data_loader.py
â”‚   â”œâ”€â”€ test_vision_preprocessing.py
â”‚   â”œâ”€â”€ test_vision_models.py
â”‚   â””â”€â”€ test_vision_evaluation.py
â”œâ”€â”€ integration/             # Testes de integraÃ§Ã£o
â”‚   â”œâ”€â”€ test_tabular_pipeline.py
â”‚   â””â”€â”€ test_vision_pipeline.py
â””â”€â”€ fixtures/                # Dados sintÃ©ticos para testes
    â”œâ”€â”€ sample_data.py
    â””â”€â”€ sample_images.py
```

### Cobertura de Testes

Os testes cobrem:

- âœ… Todas as funÃ§Ãµes dos mÃ³dulos `src/tabular/`
- âœ… Todas as funÃ§Ãµes dos mÃ³dulos `src/vision/`
- âœ… Edge cases e tratamento de erros
- âœ… ValidaÃ§Ã£o de dados de entrada
- âœ… Testes de integraÃ§Ã£o para pipelines completos
- âœ… Mocks para operaÃ§Ãµes custosas (downloads, treinamento)

**Meta de cobertura**: 80% ou mais

---

## ğŸ“š Guia Passo a Passo Completo

Este guia explica detalhadamente cada notebook do projeto, o que ele faz, o que vocÃª verÃ¡ ao executÃ¡-lo e como interpretar os resultados.

### Notebook 01: ExploraÃ§Ã£o de Dados Tabulares

#### ğŸ¯ Objetivo

Este notebook realiza uma **anÃ¡lise exploratÃ³ria de dados (EDA)** do dataset de cÃ¢ncer de mama. Ele examina as caracterÃ­sticas dos dados, identifica padrÃµes, verifica a qualidade dos dados e prepara o terreno para a modelagem.

#### ğŸ“‹ PrÃ©-requisitos

- Python 3.8+ instalado
- DependÃªncias do `requirements.txt` instaladas
- Arquivo `data/tabular/breast-cancer.csv` presente no projeto

#### ğŸ“ Passo a Passo

**Passo 1: Carregamento dos Dados**

- **O que fazer**: Execute a primeira cÃ©lula que importa as bibliotecas e carrega o dataset
- **O que vocÃª verÃ¡**: Uma tabela mostrando as primeiras 5 linhas do dataset com todas as colunas
- **O que significa**: VocÃª estÃ¡ visualizando uma amostra dos dados. Cada linha representa um paciente e cada coluna uma caracterÃ­stica medida (raio, textura, perÃ­metro, etc.)

**Passo 2: AnÃ¡lise Descritiva**

- **O que fazer**: Execute as cÃ©lulas que mostram `df.info()` e `df.describe()`
- **O que vocÃª verÃ¡**:
  - `df.info()`: Lista de todas as colunas, tipos de dados e quantidade de valores nÃ£o nulos
  - `df.describe()`: EstatÃ­sticas descritivas (mÃ©dia, desvio padrÃ£o, mÃ­nimo, mÃ¡ximo, quartis) para cada coluna numÃ©rica
- **O que significa**:
  - `info()` confirma que nÃ£o hÃ¡ valores faltantes (todos os 569 registros tÃªm valores)
  - `describe()` mostra a distribuiÃ§Ã£o dos valores. Por exemplo, se a mÃ©dia de `radius_mean` Ã© 14.1, isso indica o tamanho mÃ©dio dos nÃºcleos celulares

**Passo 3: AnÃ¡lise da VariÃ¡vel Alvo**

- **O que fazer**: Execute as cÃ©lulas que visualizam a distribuiÃ§Ã£o da variÃ¡vel `diagnosis`
- **O que vocÃª verÃ¡**:
  - Um grÃ¡fico de barras mostrando quantos casos sÃ£o Benignos (B) e quantos sÃ£o Malignos (M)
  - Um grÃ¡fico de pizza (pie chart) mostrando as proporÃ§Ãµes
  - EstatÃ­sticas de contagem
- **O que significa**:
  - VocÃª verÃ¡ aproximadamente 357 casos Benignos (62.7%) e 212 casos Malignos (37.3%)
  - Isso indica um **desbalanceamento moderado** das classes, o que Ã© importante considerar na modelagem

**Passo 4: AnÃ¡lise de CorrelaÃ§Ã£o**

- **O que fazer**: Execute as cÃ©lulas que criam a matriz de correlaÃ§Ã£o
- **O que vocÃª verÃ¡**:
  - Um mapa de calor (heatmap) colorido mostrando correlaÃ§Ãµes entre variÃ¡veis
  - Cores quentes (vermelho/laranja) indicam correlaÃ§Ã£o positiva forte
  - Cores frias (azul) indicam correlaÃ§Ã£o negativa
- **O que significa**:
  - VariÃ¡veis altamente correlacionadas (ex: `radius_mean` e `perimeter_mean`) fornecem informaÃ§Ãµes similares
  - Isso pode indicar redundÃ¢ncia, mas tambÃ©m pode ser Ãºtil para o modelo

**Passo 5: VisualizaÃ§Ã£o de DistribuiÃ§Ãµes**

- **O que fazer**: Execute as cÃ©lulas que criam histogramas e boxplots
- **O que vocÃª verÃ¡**:
  - Histogramas mostrando a distribuiÃ§Ã£o de valores para diferentes features
  - Boxplots comparando a distribuiÃ§Ã£o entre classes Benignas e Malignas
- **O que significa**:
  - Se vocÃª vÃª diferenÃ§as claras nos boxplots entre B e M, essa feature Ã© provavelmente importante para classificaÃ§Ã£o
  - Por exemplo, se `radius_worst` Ã© maior em casos Malignos, isso faz sentido clinicamente

#### ğŸ“Š SaÃ­das Esperadas

1. **Tabela de dados**: Primeiras linhas do dataset
2. **EstatÃ­sticas descritivas**: Tabela com mÃ©dias, desvios padrÃ£o, etc.
3. **GrÃ¡fico de distribuiÃ§Ã£o de classes**: Bar chart e pie chart mostrando ~62% Benigno, ~38% Maligno
4. **Matriz de correlaÃ§Ã£o**: Heatmap colorido mostrando relaÃ§Ãµes entre variÃ¡veis
5. **Histogramas**: DistribuiÃ§Ãµes de features individuais
6. **Boxplots**: ComparaÃ§Ã£o de features entre classes B e M

#### ğŸ’¡ InterpretaÃ§Ã£o dos Resultados

- **Qualidade dos dados**: Se nÃ£o hÃ¡ valores faltantes e os tipos de dados estÃ£o corretos, os dados estÃ£o prontos para modelagem
- **Desbalanceamento**: O dataset tem mais casos benignos que malignos. Isso Ã© normal, mas devemos usar estratificaÃ§Ã£o na divisÃ£o dos dados
- **Features importantes**: Features que mostram diferenÃ§as claras entre B e M nos boxplots sÃ£o candidatas a serem importantes para o modelo
- **CorrelaÃ§Ãµes**: Features muito correlacionadas (ex: radius, perimeter, area) sÃ£o relacionadas, o que Ã© esperado

#### â¡ï¸ PrÃ³ximos Passos

ApÃ³s completar este notebook, vocÃª estÃ¡ pronto para o **Notebook 02: Modelagem de Dados Tabulares**, onde os dados serÃ£o usados para treinar modelos de machine learning.

---

### Notebook 02: Modelagem de Dados Tabulares

#### ğŸ¯ Objetivo

Este notebook treina e avalia modelos de machine learning para prever se um tumor Ã© benigno ou maligno com base nas caracterÃ­sticas clÃ­nicas. VocÃª verÃ¡ dois modelos diferentes (RegressÃ£o LogÃ­stica e Random Forest) sendo treinados, comparados e interpretados.

#### ğŸ“‹ PrÃ©-requisitos

- Notebook 01 executado (para entender os dados)
- Dataset carregado e limpo
- Bibliotecas scikit-learn e SHAP instaladas

#### ğŸ“ Passo a Passo

**Passo 1: PreparaÃ§Ã£o dos Dados**

- **O que fazer**: Execute as cÃ©lulas que separam features (X) da variÃ¡vel alvo (y) e dividem os dados
- **O que vocÃª verÃ¡**:
  - Mensagens mostrando quantas features foram selecionadas (30)
  - InformaÃ§Ãµes sobre a divisÃ£o: 341 amostras de treino, 114 de validaÃ§Ã£o, 114 de teste
- **O que significa**:
  - Os dados sÃ£o divididos em trÃªs conjuntos: **treino** (para aprender), **validaÃ§Ã£o** (para ajustar) e **teste** (para avaliar final)
  - A divisÃ£o Ã© **estratificada**, mantendo a proporÃ§Ã£o de classes em cada conjunto

**Passo 2: Treinamento do Modelo 1 - RegressÃ£o LogÃ­stica**

- **O que fazer**: Execute as cÃ©lulas que criam e treinam o modelo de RegressÃ£o LogÃ­stica
- **O que vocÃª verÃ¡**:
  - Mensagem "Treinando RegressÃ£o LogÃ­stica..."
  - RelatÃ³rios de classificaÃ§Ã£o mostrando mÃ©tricas para validaÃ§Ã£o e teste
  - Tabelas com Precision, Recall, F1-Score para cada classe
- **O que significa**:
  - **Precision**: Quando o modelo diz "Maligno", quantas vezes estÃ¡ correto (~97%)
  - **Recall**: Quantos casos malignos o modelo consegue detectar (~93%)
  - **F1-Score**: MÃ©dia balanceada entre Precision e Recall (~95%)

**Passo 3: Treinamento do Modelo 2 - Random Forest**

- **O que fazer**: Execute as cÃ©lulas que criam e treinam o modelo Random Forest
- **O que vocÃª verÃ¡**:
  - Mensagem "Treinando Random Forest..."
  - RelatÃ³rios de classificaÃ§Ã£o similares ao modelo anterior
  - MÃ©tricas geralmente ligeiramente melhores
- **O que significa**:
  - Random Forest Ã© um modelo mais complexo que combina mÃºltiplas Ã¡rvores de decisÃ£o
  - Geralmente apresenta melhor desempenho, mas Ã© menos interpretÃ¡vel

**Passo 4: ComparaÃ§Ã£o dos Modelos**

- **O que fazer**: Execute as cÃ©lulas que comparam os dois modelos
- **O que vocÃª verÃ¡**:
  - Uma tabela comparativa mostrando Accuracy, Precision, Recall e F1-Score lado a lado
  - Um grÃ¡fico de barras comparando as mÃ©tricas
  - IdentificaÃ§Ã£o do melhor modelo
- **O que significa**:
  - Random Forest geralmente apresenta Accuracy ~97.4% vs ~96.5% da RegressÃ£o LogÃ­stica
  - O melhor modelo Ã© selecionado para uso futuro

**Passo 5: Matriz de ConfusÃ£o**

- **O que fazer**: Execute as cÃ©lulas que geram a matriz de confusÃ£o
- **O que vocÃª verÃ¡**:
  - Uma matriz 2x2 mostrando:
    - **Verdadeiros Negativos (TN)**: Casos benignos corretamente identificados
    - **Falsos Positivos (FP)**: Casos benignos classificados como malignos (alarmes falsos)
    - **Falsos Negativos (FN)**: Casos malignos classificados como benignos (perigosos!)
    - **Verdadeiros Positivos (TP)**: Casos malignos corretamente identificados
- **O que significa**:
  - **Falsos Negativos sÃ£o crÃ­ticos**: Um caso maligno nÃ£o detectado pode ser perigoso
  - O modelo ideal tem poucos ou nenhum falso negativo

**Passo 6: Feature Importance**

- **O que fazer**: Execute as cÃ©lulas que mostram a importÃ¢ncia das features
- **O que vocÃª verÃ¡**:
  - Um grÃ¡fico de barras horizontal mostrando as features mais importantes
  - Top 10-15 features listadas com suas importÃ¢ncias
- **O que significa**:
  - Features como `concave points_worst` e `perimeter_worst` sÃ£o as mais importantes
  - Isso indica que caracterÃ­sticas de concavidade e tamanho sÃ£o mais preditivas

**Passo 7: AnÃ¡lise SHAP**

- **O que fazer**: Execute as cÃ©lulas que calculam e visualizam valores SHAP
- **O que vocÃª verÃ¡**:
  - **Summary Plot**: Um grÃ¡fico mostrando como cada feature afeta as prediÃ§Ãµes
  - **Bar Plot**: ImportÃ¢ncia mÃ©dia das features segundo SHAP
  - **Waterfall Plot**: ExplicaÃ§Ã£o de uma prediÃ§Ã£o especÃ­fica
- **O que significa**:
  - SHAP explica **por que** o modelo fez cada prediÃ§Ã£o
  - Valores SHAP positivos (vermelho) aumentam a probabilidade de "Maligno"
  - Valores SHAP negativos (azul) diminuem a probabilidade de "Maligno"

**Passo 8: DiscussÃ£o CrÃ­tica**

- **O que fazer**: Leia as cÃ©lulas de discussÃ£o sobre limitaÃ§Ãµes e consideraÃ§Ãµes Ã©ticas
- **O que vocÃª verÃ¡**:
  - Lista de limitaÃ§Ãµes do modelo
  - ConsideraÃ§Ãµes sobre uso prÃ¡tico
  - ConsideraÃ§Ãµes Ã©ticas e mÃ©dicas
- **O que significa**:
  - O modelo tem limitaÃ§Ãµes (dataset pequeno, nÃ£o considera contexto completo)
  - **Nunca deve substituir o diagnÃ³stico mÃ©dico**
  - Deve ser usado apenas como ferramenta de apoio

#### ğŸ“Š SaÃ­das Esperadas

1. **RelatÃ³rios de classificaÃ§Ã£o**: Tabelas com mÃ©tricas para cada modelo
2. **GrÃ¡fico comparativo**: Barras mostrando Accuracy, Precision, Recall, F1-Score
3. **Matriz de confusÃ£o**: VisualizaÃ§Ã£o 2x2 dos acertos e erros
4. **Feature importance**: GrÃ¡fico de barras com top features
5. **SHAP Summary Plot**: VisualizaÃ§Ã£o da importÃ¢ncia global das features
6. **SHAP Bar Plot**: ImportÃ¢ncia mÃ©dia segundo SHAP
7. **SHAP Waterfall Plot**: ExplicaÃ§Ã£o de uma prediÃ§Ã£o especÃ­fica

#### ğŸ’¡ InterpretaÃ§Ã£o dos Resultados

- **MÃ©tricas altas (>95%)**: Indicam que o modelo estÃ¡ funcionando bem, mas lembre-se: em medicina, atÃ© 1% de erro pode ser significativo
- **Recall de ~93%**: Significa que 7% dos casos malignos nÃ£o sÃ£o detectados. Isso Ã© crÃ­tico e precisa ser melhorado
- **Precision de 100% (Random Forest)**: Significa que quando o modelo diz "maligno", estÃ¡ sempre correto - nÃ£o hÃ¡ falsos alarmes
- **Feature importance**: Confirma que caracterÃ­sticas de tamanho e forma sÃ£o mais importantes que textura
- **SHAP**: Fornece transparÃªncia sobre as decisÃµes do modelo, essencial para confianÃ§a mÃ©dica

#### â¡ï¸ PrÃ³ximos Passos

ApÃ³s completar este notebook, vocÃª pode:

- Explorar os notebooks de visÃ£o computacional (03-06) para classificaÃ§Ã£o de imagens
- Usar o modelo treinado para fazer prediÃ§Ãµes em novos dados
- Ajustar hiperparÃ¢metros para melhorar o desempenho

---

### Notebook 03: ExploraÃ§Ã£o de Imagens de Pneumonia

#### ğŸ¯ Objetivo

Este notebook realiza uma anÃ¡lise exploratÃ³ria do dataset de imagens de raio-X de tÃ³rax para detecÃ§Ã£o de pneumonia. Ele baixa o dataset, explora sua estrutura, visualiza amostras de imagens e analisa a distribuiÃ§Ã£o das classes.

#### ğŸ“‹ PrÃ©-requisitos

- Python 3.8+ instalado
- DependÃªncias instaladas (especialmente `kagglehub` para download)
- ConexÃ£o com internet (para baixar o dataset do Kaggle)

#### ğŸ“ Passo a Passo

**Passo 1: Download do Dataset**

- **O que fazer**: Execute a cÃ©lula que baixa o dataset do Kaggle
- **O que vocÃª verÃ¡**:
  - Mensagens de progresso do download
  - Caminho onde o dataset foi salvo
  - Pode levar alguns minutos dependendo da conexÃ£o
- **O que significa**:
  - O dataset serÃ¡ baixado automaticamente usando `kagglehub`
  - As imagens serÃ£o organizadas em pastas: `train/NORMAL/`, `train/PNEUMONIA/`, `test/`, `val/`

**Passo 2: AnÃ¡lise da Estrutura**

- **O que fazer**: Execute as cÃ©lulas que analisam a estrutura de diretÃ³rios
- **O que vocÃª verÃ¡**:
  - Contagem de imagens em cada pasta
  - DistribuiÃ§Ã£o entre classes (Normal vs Pneumonia)
  - Estrutura de diretÃ³rios
- **O que significa**:
  - VocÃª verÃ¡ milhares de imagens (ex: ~1300 Normal, ~3900 Pneumonia no treino)
  - HÃ¡ um desbalanceamento significativo (mais casos de pneumonia)
  - Os dados jÃ¡ vÃªm divididos em treino/teste/validaÃ§Ã£o

**Passo 3: VisualizaÃ§Ã£o de Amostras**

- **O que fazer**: Execute as cÃ©lulas que mostram imagens de exemplo
- **O que vocÃª verÃ¡**:
  - Grid de imagens mostrando exemplos de cada classe
  - Imagens de raio-X de tÃ³rax em escala de cinza
  - Labels indicando "Normal" ou "Pneumonia"
- **O que significa**:
  - **Normal**: PulmÃµes limpos, sem opacidades
  - **Pneumonia**: Opacidades brancas (infiltrados) indicando infecÃ§Ã£o
  - As diferenÃ§as podem ser sutis, o que torna o problema desafiador

**Passo 4: AnÃ¡lise de DimensÃµes**

- **O que fazer**: Execute as cÃ©lulas que verificam as dimensÃµes das imagens
- **O que vocÃª verÃ¡**:
  - EstatÃ­sticas sobre largura, altura e formato das imagens
  - Algumas imagens podem ter tamanhos diferentes
- **O que significa**:
  - As imagens precisarÃ£o ser redimensionadas para um tamanho uniforme antes do treinamento
  - Geralmente redimensionamos para 224x224 pixels

**Passo 5: AnÃ¡lise de Qualidade**

- **O que fazer**: Execute as cÃ©lulas que verificam a qualidade das imagens
- **O que vocÃª verÃ¡**:
  - VerificaÃ§Ã£o de imagens corrompidas ou invÃ¡lidas
  - EstatÃ­sticas sobre canais de cor (RGB vs escala de cinza)
- **O que significa**:
  - A maioria das imagens de raio-X sÃ£o em escala de cinza, mas algumas podem ter 3 canais
  - Imagens corrompidas serÃ£o identificadas e podem ser removidas

**Passo 6: DistribuiÃ§Ã£o de Classes**

- **O que fazer**: Execute as cÃ©lulas que visualizam a distribuiÃ§Ã£o
- **O que vocÃª verÃ¡**:
  - GrÃ¡ficos de barras mostrando contagem por classe
  - GrÃ¡ficos de pizza mostrando proporÃ§Ãµes
- **O que significa**:
  - HÃ¡ mais imagens de pneumonia que normais (desbalanceamento)
  - Isso serÃ¡ tratado durante o treinamento com tÃ©cnicas como data augmentation e class weights

#### ğŸ“Š SaÃ­das Esperadas

1. **Mensagens de download**: Progresso do download do dataset
2. **EstatÃ­sticas de estrutura**: Contagem de imagens por pasta e classe
3. **Grid de imagens**: VisualizaÃ§Ã£o de amostras de cada classe
4. **AnÃ¡lise de dimensÃµes**: EstatÃ­sticas sobre tamanhos das imagens
5. **GrÃ¡ficos de distribuiÃ§Ã£o**: Barras e pizza mostrando proporÃ§Ãµes de classes

#### ğŸ’¡ InterpretaÃ§Ã£o dos Resultados

- **Dataset grande**: Milhares de imagens fornecem dados suficientes para treinar uma CNN
- **Desbalanceamento**: Mais casos de pneumonia Ã© esperado em um dataset mÃ©dico real
- **Qualidade variÃ¡vel**: Imagens podem ter diferentes resoluÃ§Ãµes e qualidades, o que Ã© normal
- **DiferenÃ§as sutis**: As diferenÃ§as entre Normal e Pneumonia podem ser difÃ­ceis de ver a olho nu, mas o modelo aprenderÃ¡ padrÃµes

#### â¡ï¸ PrÃ³ximos Passos

ApÃ³s completar este notebook, vocÃª estÃ¡ pronto para o **Notebook 04: Modelagem CNN para Pneumonia**, onde uma rede neural convolucional serÃ¡ treinada para classificar as imagens.

---

### Notebook 04: Modelagem CNN para Pneumonia

#### ğŸ¯ Objetivo

Este notebook treina uma **Rede Neural Convolucional (CNN)** para classificar imagens de raio-X de tÃ³rax como Normal ou Pneumonia. VocÃª verÃ¡ o processo completo: prÃ©-processamento, treinamento, avaliaÃ§Ã£o e interpretabilidade com Grad-CAM.

#### ğŸ“‹ PrÃ©-requisitos

- Notebook 03 executado (dataset baixado e explorado)
- TensorFlow/Keras instalado
- GPU opcional (mas recomendado para treinamento mais rÃ¡pido)

#### ğŸ“ Passo a Passo

**Passo 1: Carregamento e DivisÃ£o dos Dados**

- **O que fazer**: Execute as cÃ©lulas que carregam as imagens e dividem em treino/validaÃ§Ã£o/teste
- **O que vocÃª verÃ¡**:
  - Mensagens mostrando quantas imagens foram carregadas
  - InformaÃ§Ãµes sobre a divisÃ£o: 60% treino, 20% validaÃ§Ã£o, 20% teste
  - EstatÃ­sticas de distribuiÃ§Ã£o de classes
- **O que significa**:
  - As imagens sÃ£o carregadas e organizadas em batches para eficiÃªncia
  - A divisÃ£o mantÃ©m a proporÃ§Ã£o de classes (estratificaÃ§Ã£o)

**Passo 2: Data Augmentation**

- **O que fazer**: Execute as cÃ©lulas que configuram data augmentation
- **O que vocÃª verÃ¡**:
  - ConfiguraÃ§Ãµes de transformaÃ§Ãµes: rotaÃ§Ã£o, zoom, deslocamento, etc.
- **O que significa**:
  - **Data augmentation** cria variaÃ§Ãµes das imagens (rotacionadas, ampliadas, etc.)
  - Isso aumenta a diversidade do dataset e reduz overfitting
  - Apenas aplicado no conjunto de treino

**Passo 3: CriaÃ§Ã£o do Modelo CNN**

- **O que fazer**: Execute as cÃ©lulas que criam a arquitetura da CNN
- **O que vocÃª verÃ¡**:
  - Resumo da arquitetura mostrando todas as camadas
  - NÃºmero total de parÃ¢metros (milhÃµes)
  - Estrutura: camadas convolucionais â†’ pooling â†’ camadas densas
- **O que significa**:
  - **Camadas convolucionais**: Detectam padrÃµes (bordas, texturas, formas)
  - **Pooling**: Reduz dimensÃ£o, mantendo informaÃ§Ãµes importantes
  - **Camadas densas**: Fazem a classificaÃ§Ã£o final

**Passo 4: CompilaÃ§Ã£o do Modelo**

- **O que fazer**: Execute as cÃ©lulas que compilam o modelo
- **O que vocÃª verÃ¡**:
  - ConfiguraÃ§Ãµes: otimizador (Adam), funÃ§Ã£o de loss, mÃ©tricas
- **O que significa**:
  - **Adam**: Algoritmo de otimizaÃ§Ã£o eficiente
  - **Categorical Crossentropy**: FunÃ§Ã£o de loss adequada para classificaÃ§Ã£o
  - **MÃ©tricas**: Accuracy, Precision, Recall serÃ£o monitoradas

**Passo 5: Treinamento**

- **O que fazer**: Execute a cÃ©lula que inicia o treinamento
- **O que vocÃª verÃ¡**:
  - Progresso por Ã©poca mostrando:
    - Loss (erro) no treino e validaÃ§Ã£o
    - Accuracy no treino e validaÃ§Ã£o
    - Tempo por Ã©poca
  - Pode levar de 30 minutos a vÃ¡rias horas dependendo do hardware
- **O que significa**:
  - O modelo estÃ¡ aprendendo a distinguir Normal de Pneumonia
  - **Loss diminuindo**: O modelo estÃ¡ melhorando
  - **Accuracy aumentando**: O modelo estÃ¡ acertando mais
  - **Early stopping**: O treinamento para automaticamente se nÃ£o melhorar

**Passo 6: VisualizaÃ§Ã£o do HistÃ³rico de Treinamento**

- **O que fazer**: Execute as cÃ©lulas que plotam grÃ¡ficos do histÃ³rico
- **O que vocÃª verÃ¡**:
  - GrÃ¡ficos de Loss (treino vs validaÃ§Ã£o) ao longo das Ã©pocas
  - GrÃ¡ficos de Accuracy (treino vs validaÃ§Ã£o) ao longo das Ã©pocas
- **O que significa**:
  - **Curvas convergindo**: O modelo estÃ¡ aprendendo bem
  - **Gap grande entre treino e validaÃ§Ã£o**: PossÃ­vel overfitting
  - **ValidaÃ§Ã£o melhorando**: O modelo estÃ¡ generalizando bem

**Passo 7: AvaliaÃ§Ã£o no Conjunto de Teste**

- **O que fazer**: Execute as cÃ©lulas que avaliam o modelo no conjunto de teste
- **O que vocÃª verÃ¡**:
  - MÃ©tricas finais: Accuracy, Precision, Recall, F1-Score
  - Matriz de confusÃ£o
  - Curva ROC e AUC
- **O que significa**:
  - **Accuracy > 80%**: Bom desempenho para uma CNN simples
  - **Matriz de confusÃ£o**: Mostra quantos casos foram classificados corretamente
  - **ROC-AUC**: Mede a capacidade de distinguir entre classes (quanto maior, melhor)

**Passo 8: VisualizaÃ§Ã£o de PrediÃ§Ãµes**

- **O que fazer**: Execute as cÃ©lulas que mostram prediÃ§Ãµes em imagens de teste
- **O que vocÃª verÃ¡**:
  - Grid de imagens com prediÃ§Ãµes
  - Labels mostrando: Classe verdadeira vs PrediÃ§Ã£o vs ConfianÃ§a
  - Imagens corretas e incorretas destacadas
- **O que significa**:
  - **ConfianÃ§a alta (>90%)**: O modelo estÃ¡ muito certo
  - **ConfianÃ§a baixa (<70%)**: O modelo estÃ¡ incerto
  - **Erros**: Casos difÃ­ceis que o modelo confundiu

**Passo 9: Grad-CAM (Interpretabilidade)**

- **O que fazer**: Execute as cÃ©lulas que geram visualizaÃ§Ãµes Grad-CAM
- **O que vocÃª verÃ¡**:
  - Imagens originais lado a lado com heatmaps coloridos
  - RegiÃµes em vermelho/laranja: Ã¡reas que o modelo considera importantes
  - SuperposiÃ§Ã£o do heatmap na imagem original
- **O que significa**:
  - **Grad-CAM** mostra **onde** o modelo estÃ¡ olhando
  - RegiÃµes destacadas devem corresponder a Ã¡reas clinicamente relevantes (pulmÃµes)
  - Se o modelo foca em Ã¡reas irrelevantes, pode indicar problemas

#### ğŸ“Š SaÃ­das Esperadas

1. **Resumo da arquitetura**: Estrutura completa da CNN
2. **Progresso de treinamento**: MÃ©tricas por Ã©poca
3. **GrÃ¡ficos de histÃ³rico**: Loss e Accuracy ao longo do tempo
4. **MÃ©tricas finais**: Tabela com Accuracy, Precision, Recall, F1-Score
5. **Matriz de confusÃ£o**: VisualizaÃ§Ã£o 2x2 dos acertos e erros
6. **Curva ROC**: GrÃ¡fico mostrando performance de classificaÃ§Ã£o
7. **Grid de prediÃ§Ãµes**: Imagens com prediÃ§Ãµes e confianÃ§as
8. **Grad-CAM heatmaps**: VisualizaÃ§Ãµes mostrando regiÃµes importantes

#### ğŸ’¡ InterpretaÃ§Ã£o dos Resultados

- **Accuracy > 80%**: Bom desempenho, mas em medicina sempre buscamos melhorar
- **Recall alto**: Importante para nÃ£o perder casos de pneumonia
- **Grad-CAM focado nos pulmÃµes**: Indica que o modelo estÃ¡ aprendendo padrÃµes corretos
- **Overfitting**: Se accuracy de treino >> accuracy de validaÃ§Ã£o, o modelo estÃ¡ decorando os dados
- **Tempo de treinamento**: CNNs sÃ£o computacionalmente intensivas, mas os resultados valem a pena

#### â¡ï¸ PrÃ³ximos Passos

ApÃ³s completar este notebook, vocÃª pode:

- Explorar os notebooks de cÃ¢ncer de mama (05-06)
- Experimentar diferentes arquiteturas de CNN
- Ajustar hiperparÃ¢metros para melhorar o desempenho

---

### Notebook 05: ExploraÃ§Ã£o de Mamografias

#### ğŸ¯ Objetivo

Este notebook realiza uma anÃ¡lise exploratÃ³ria do dataset de mamografias (CBIS-DDSM) para detecÃ§Ã£o de cÃ¢ncer de mama. Similar ao notebook 03, mas focado em imagens de mamografia.

#### ğŸ“‹ PrÃ©-requisitos

- Python 3.8+ instalado
- DependÃªncias instaladas (especialmente `kagglehub`)
- ConexÃ£o com internet
- **Nota**: Este dataset Ã© maior e pode levar mais tempo para baixar

#### ğŸ“ Passo a Passo

**Passo 1: Download do Dataset**

- **O que fazer**: Execute a cÃ©lula que baixa o dataset CBIS-DDSM
- **O que vocÃª verÃ¡**:
  - Mensagens de progresso (pode levar 10-30 minutos)
  - Caminho onde o dataset foi salvo
  - Estrutura de diretÃ³rios complexa (o dataset CBIS-DDSM tem estrutura aninhada)
- **O que significa**:
  - Este dataset Ã© maior e mais complexo que o de pneumonia
  - As imagens sÃ£o de alta resoluÃ§Ã£o (mamografias detalhadas)
  - Estrutura: `train/BENIGN/`, `train/MALIGNANT/`, etc.

**Passo 2: AnÃ¡lise da Estrutura**

- **O que fazer**: Execute as cÃ©lulas que analisam a estrutura
- **O que vocÃª verÃ¡**:
  - Contagem de imagens por classe
  - Estrutura de diretÃ³rios (pode ser aninhada)
  - EstatÃ­sticas de distribuiÃ§Ã£o
- **O que significa**:
  - Dataset pode ter centenas ou milhares de imagens
  - DistribuiÃ§Ã£o entre Benigno e Maligno
  - Estrutura pode requerer navegaÃ§Ã£o em subdiretÃ³rios

**Passo 3: VisualizaÃ§Ã£o de Amostras**

- **O que fazer**: Execute as cÃ©lulas que mostram imagens de exemplo
- **O que vocÃª verÃ¡**:
  - Grid de mamografias em escala de cinza
  - Imagens de alta resoluÃ§Ã£o mostrando tecido mamÃ¡rio
  - Labels indicando "Benigno" ou "Maligno"
- **O que significa**:
  - **Mamografias**: Imagens de raio-X das mamas
  - **LesÃµes benignas**: Massas nÃ£o cancerosas
  - **LesÃµes malignas**: CÃ¢ncer de mama
  - DiferenÃ§as podem ser muito sutis e requerem anÃ¡lise especializada

**Passo 4: AnÃ¡lise de DimensÃµes e Qualidade**

- **O que fazer**: Execute as cÃ©lulas que verificam dimensÃµes e qualidade
- **O que vocÃª verÃ¡**:
  - EstatÃ­sticas sobre tamanhos das imagens (geralmente grandes, ex: 2000x3000 pixels)
  - VerificaÃ§Ã£o de imagens corrompidas
  - InformaÃ§Ãµes sobre formato (geralmente DICOM ou PNG)
- **O que significa**:
  - Imagens de alta resoluÃ§Ã£o precisarÃ£o ser redimensionadas para treinamento (ex: 256x256)
  - Formato DICOM Ã© comum em imagens mÃ©dicas e pode requerer conversÃ£o

**Passo 5: DistribuiÃ§Ã£o de Classes**

- **O que fazer**: Execute as cÃ©lulas que visualizam a distribuiÃ§Ã£o
- **O que vocÃª verÃ¡**:
  - GrÃ¡ficos mostrando proporÃ§Ã£o de Benigno vs Maligno
  - EstatÃ­sticas de contagem
- **O que significa**:
  - Pode haver desbalanceamento (mais casos benignos Ã© comum)
  - Isso serÃ¡ tratado durante o treinamento

#### ğŸ“Š SaÃ­das Esperadas

1. **Mensagens de download**: Progresso (pode ser longo)
2. **EstatÃ­sticas de estrutura**: Contagem e organizaÃ§Ã£o de imagens
3. **Grid de mamografias**: VisualizaÃ§Ã£o de amostras
4. **AnÃ¡lise de dimensÃµes**: Tamanhos das imagens (geralmente grandes)
5. **GrÃ¡ficos de distribuiÃ§Ã£o**: ProporÃ§Ãµes de classes

#### ğŸ’¡ InterpretaÃ§Ã£o dos Resultados

- **Dataset complexo**: Estrutura aninhada Ã© comum em datasets mÃ©dicos profissionais
- **Alta resoluÃ§Ã£o**: Imagens detalhadas sÃ£o importantes para detectar lesÃµes pequenas
- **DiferenÃ§as sutis**: Distinguir benigno de maligno Ã© desafiador mesmo para especialistas
- **Desbalanceamento**: Mais casos benignos Ã© esperado em dados reais

#### â¡ï¸ PrÃ³ximos Passos

ApÃ³s completar este notebook, vocÃª estÃ¡ pronto para o **Notebook 06: Modelagem CNN para CÃ¢ncer de Mama**, onde uma CNN serÃ¡ treinada para classificar as mamografias.

---

### Notebook 06: Modelagem CNN para CÃ¢ncer de Mama

#### ğŸ¯ Objetivo

Este notebook treina uma **CNN** para classificar mamografias como Benignas ou Malignas. Similar ao notebook 04, mas adaptado para imagens em escala de cinza e com arquitetura otimizada para o problema especÃ­fico.

#### ğŸ“‹ PrÃ©-requisitos

- Notebook 05 executado (dataset baixado)
- TensorFlow/Keras instalado
- GPU recomendado (treinamento pode ser longo)

#### ğŸ“ Passo a Passo

**Passo 1: Carregamento e PrÃ©-processamento**

- **O que fazer**: Execute as cÃ©lulas que carregam e preprocessam as imagens
- **O que vocÃª verÃ¡**:
  - Mensagens sobre carregamento de imagens
  - ConversÃ£o para escala de cinza (1 canal em vez de 3)
  - Redimensionamento para 256x256 pixels
  - DivisÃ£o em treino/validaÃ§Ã£o/teste
- **O que significa**:
  - Mamografias sÃ£o naturalmente em escala de cinza
  - Redimensionamento Ã© necessÃ¡rio para eficiÃªncia computacional
  - Tamanho 256x256 Ã© um bom equilÃ­brio entre detalhe e velocidade

**Passo 2: Data Augmentation**

- **O que fazer**: Execute as cÃ©lulas que configuram augmentation
- **O que vocÃª verÃ¡**:
  - ConfiguraÃ§Ãµes similares ao notebook 04, mas adaptadas para escala de cinza
  - RotaÃ§Ã£o, zoom, deslocamento, brightness adjustment
- **O que significa**:
  - Augmentation Ã© especialmente importante para datasets menores
  - VariaÃ§Ãµes de brilho simulam diferentes condiÃ§Ãµes de imagem

**Passo 3: CriaÃ§Ã£o do Modelo CNN**

- **O que fazer**: Execute as cÃ©lulas que criam a arquitetura
- **O que vocÃª verÃ¡**:
  - Arquitetura com 5 blocos convolucionais (mais profunda que pneumonia)
  - Global Average Pooling (tÃ©cnica avanÃ§ada para reduzir overfitting)
  - Batch Normalization e Dropout para regularizaÃ§Ã£o
- **O que significa**:
  - Arquitetura mais profunda captura padrÃµes mais complexos
  - TÃ©cnicas de regularizaÃ§Ã£o previnem overfitting
  - Global Average Pooling reduz parÃ¢metros e melhora generalizaÃ§Ã£o

**Passo 4: CompilaÃ§Ã£o com Focal Loss (Opcional)**

- **O que fazer**: Execute as cÃ©lulas que compilam o modelo
- **O que vocÃª verÃ¡**:
  - OpÃ§Ã£o de usar Focal Loss ou Categorical Crossentropy
  - Focal Loss Ã© especialmente Ãºtil para classes desbalanceadas
- **O que significa**:
  - **Focal Loss**: Foca em exemplos difÃ­ceis, Ãºtil quando hÃ¡ desbalanceamento
  - **Class Weights**: Ajusta a importÃ¢ncia de cada classe durante treinamento

**Passo 5: Treinamento**

- **O que fazer**: Execute a cÃ©lula que inicia o treinamento
- **O que vocÃª verÃ¡**:
  - Progresso similar ao notebook 04
  - Pode levar mais tempo devido Ã  arquitetura mais profunda
  - Early stopping e reduÃ§Ã£o de learning rate automÃ¡ticos
- **O que significa**:
  - O modelo estÃ¡ aprendendo padrÃµes sutis em mamografias
  - Callbacks automÃ¡ticos otimizam o treinamento

**Passo 6: AvaliaÃ§Ã£o e MÃ©tricas**

- **O que fazer**: Execute as cÃ©lulas de avaliaÃ§Ã£o
- **O que vocÃª verÃ¡**:
  - MÃ©tricas completas: Accuracy, Precision, Recall, F1-Score
  - Matriz de confusÃ£o
  - Curva ROC
  - AnÃ¡lise por classe
- **O que significa**:
  - **Recall alto para Maligno**: CrÃ­tico para nÃ£o perder casos de cÃ¢ncer
  - **Precision alta**: Evita alarmes falsos e biÃ³psias desnecessÃ¡rias
  - MÃ©tricas balanceadas indicam bom desempenho geral

**Passo 7: Grad-CAM**

- **O que fazer**: Execute as cÃ©lulas que geram Grad-CAM
- **O que vocÃª verÃ¡**:
  - Heatmaps mostrando regiÃµes importantes nas mamografias
  - SuperposiÃ§Ã£o nas imagens originais
  - AnÃ¡lise de casos corretos e incorretos
- **O que significa**:
  - RegiÃµes destacadas devem corresponder a lesÃµes suspeitas
  - Se o modelo foca em Ã¡reas irrelevantes, pode indicar problemas
  - Grad-CAM Ã© essencial para validaÃ§Ã£o clÃ­nica

**Passo 8: ValidaÃ§Ã£o e DiscussÃ£o**

- **O que fazer**: Leia as cÃ©lulas de discussÃ£o sobre resultados
- **O que vocÃª verÃ¡**:
  - AnÃ¡lise crÃ­tica do desempenho
  - LimitaÃ§Ãµes do modelo
  - ConsideraÃ§Ãµes para uso clÃ­nico
- **O que significa**:
  - Mesmo com alta accuracy, o modelo tem limitaÃ§Ãµes
  - **Nunca deve substituir diagnÃ³stico mÃ©dico**
  - Pode ser usado como ferramenta de triagem/apoio

#### ğŸ“Š SaÃ­das Esperadas

1. **Resumo da arquitetura**: CNN com 5 blocos convolucionais
2. **Progresso de treinamento**: MÃ©tricas por Ã©poca
3. **GrÃ¡ficos de histÃ³rico**: Loss e Accuracy
4. **MÃ©tricas finais**: Tabela completa de avaliaÃ§Ã£o
5. **Matriz de confusÃ£o**: Performance detalhada
6. **Curva ROC**: Capacidade de classificaÃ§Ã£o
7. **Grad-CAM heatmaps**: RegiÃµes importantes nas mamografias

#### ğŸ’¡ InterpretaÃ§Ã£o dos Resultados

- **Accuracy > 80%**: Bom, mas em cÃ¢ncer sempre buscamos melhorar
- **Recall para Maligno > 90%**: Essencial - nÃ£o podemos perder casos de cÃ¢ncer
- **Grad-CAM focado em lesÃµes**: Valida que o modelo estÃ¡ aprendendo padrÃµes corretos
- **Focal Loss**: Pode melhorar performance em classes desbalanceadas
- **Arquitetura profunda**: Captura padrÃµes complexos, mas requer mais dados

#### â¡ï¸ PrÃ³ximos Passos

ApÃ³s completar este notebook, vocÃª pode explorar os notebooks de diabetes (07-08) ou ajustar hiperparÃ¢metros para melhorar o desempenho.

---

### Notebook 07: ExploraÃ§Ã£o de Diabetes

#### ğŸ¯ Objetivo

Este notebook realiza uma anÃ¡lise exploratÃ³ria do dataset de diabetes, focando em identificar valores ausentes mascarados como zero, analisar distribuiÃ§Ãµes e correlaÃ§Ãµes.

#### ğŸ“‹ PrÃ©-requisitos

- Python 3.8+ instalado
- DependÃªncias do `requirements.txt` instaladas
- Arquivo `data/tabular/diabetes.csv` presente no projeto

#### ğŸ“ Passo a Passo

**Passo 1: Carregamento dos Dados**

- Carregar dataset de diabetes
- Visualizar primeiras linhas
- Verificar informaÃ§Ãµes gerais

**Passo 2: AnÃ¡lise Descritiva**

- EstatÃ­sticas descritivas (mÃ©dia, desvio padrÃ£o, quartis)
- Identificar tipos de dados
- Verificar valores ausentes explÃ­citos

**Passo 3: IdentificaÃ§Ã£o de Valores Ausentes**

- Identificar valores zero que representam dados ausentes
- Analisar Glucose, BloodPressure, SkinThickness, Insulin, BMI
- Visualizar quantidade e percentual de zeros

**Passo 4: AnÃ¡lise da VariÃ¡vel Alvo**

- DistribuiÃ§Ã£o de classes (NÃ£o DiabÃ©tico vs DiabÃ©tico)
- Identificar desbalanceamento (~65% vs ~35%)
- VisualizaÃ§Ãµes (barras e pizza)

**Passo 5: DistribuiÃ§Ã£o das Features por Classe**

- Histogramas comparando distribuiÃ§Ãµes entre classes
- Boxplots mostrando diferenÃ§as
- Identificar features mais discriminativas

**Passo 6: AnÃ¡lise de CorrelaÃ§Ã£o**

- Matriz de correlaÃ§Ã£o completa
- CorrelaÃ§Ã£o de cada feature com Outcome
- Identificar features mais relevantes (geralmente Glucose)

#### ğŸ“Š SaÃ­das Esperadas

1. EstatÃ­sticas descritivas do dataset
2. AnÃ¡lise de valores zero que representam ausentes
3. DistribuiÃ§Ã£o de classes mostrando desbalanceamento
4. Histogramas e boxplots por classe
5. Matriz de correlaÃ§Ã£o e correlaÃ§Ãµes com Outcome

#### ğŸ’¡ InterpretaÃ§Ã£o dos Resultados

- **Desbalanceamento Moderado**: 65% vs 35% requer atenÃ§Ã£o na modelagem
- **Valores Zero sÃ£o Ausentes**: Zeros em Glucose, BloodPressure, etc. devem ser tratados
- **Glucose Ã© Mais Importante**: Geralmente a feature mais correlacionada com Outcome
- **Tratamento NecessÃ¡rio**: ImputaÃ§Ã£o de valores ausentes Ã© crÃ­tica

#### â¡ï¸ PrÃ³ximos Passos

ApÃ³s completar este notebook, vocÃª estÃ¡ pronto para o **Notebook 08: Modelagem de Diabetes**, onde os dados serÃ£o usados para treinar modelos de machine learning.

---

### Notebook 08: Modelagem de Diabetes

#### ğŸ¯ Objetivo

Este notebook treina e avalia trÃªs modelos de machine learning para prever diagnÃ³stico de diabetes: RegressÃ£o LogÃ­stica, Random Forest e KNN.

#### ğŸ“‹ PrÃ©-requisitos

- Notebook 07 executado (para entender os dados)
- Dataset carregado e analisado
- Bibliotecas scikit-learn e SHAP instaladas

#### ğŸ“ Passo a Passo

**Passo 1: PreparaÃ§Ã£o dos Dados**

- Tratamento de valores zero como ausentes
- ImputaÃ§Ã£o com mÃ©dia
- DivisÃ£o treino/validaÃ§Ã£o/teste (60/20/20)

**Passo 2: Treinamento do Modelo 1 - RegressÃ£o LogÃ­stica**

- CriaÃ§Ã£o e treinamento do modelo
- AvaliaÃ§Ã£o em validaÃ§Ã£o e teste
- MÃ©tricas: Accuracy, Precision, Recall, F1-Score

**Passo 3: Treinamento do Modelo 2 - Random Forest**

- CriaÃ§Ã£o e treinamento do modelo
- AvaliaÃ§Ã£o em validaÃ§Ã£o e teste
- Feature importance

**Passo 4: Treinamento do Modelo 3 - KNN**

- CriaÃ§Ã£o e treinamento do modelo
- AvaliaÃ§Ã£o em validaÃ§Ã£o e teste
- StandardScaler essencial para KNN

**Passo 5: ComparaÃ§Ã£o dos Modelos**

- ComparaÃ§Ã£o de mÃ©tricas entre os trÃªs modelos
- VisualizaÃ§Ã£o comparativa
- IdentificaÃ§Ã£o do melhor modelo

**Passo 6: Matriz de ConfusÃ£o**

- VisualizaÃ§Ã£o da matriz para o melhor modelo
- AnÃ¡lise de falsos positivos e negativos

**Passo 7: Feature Importance e SHAP**

- ImportÃ¢ncia das features (Random Forest)
- AnÃ¡lise SHAP para interpretabilidade

**Passo 8: DiscussÃ£o CrÃ­tica**

- LimitaÃ§Ãµes do modelo
- Viabilidade de uso prÃ¡tico
- ConsideraÃ§Ãµes Ã©ticas

#### ğŸ“Š SaÃ­das Esperadas

1. RelatÃ³rios de classificaÃ§Ã£o para cada modelo
2. ComparaÃ§Ã£o de mÃ©tricas entre os trÃªs modelos
3. Matriz de confusÃ£o do melhor modelo
4. Feature importance e SHAP plots
5. DiscussÃ£o crÃ­tica e limitaÃ§Ãµes

#### ğŸ’¡ InterpretaÃ§Ã£o dos Resultados

- **Desempenho Moderado**: ~75-82% accuracy Ã© esperado (menor que cÃ¢ncer de mama devido Ã  complexidade)
- **Random Forest Geralmente Melhor**: TendÃªncia de melhor desempenho
- **Glucose Importante**: Feature mais relevante para prediÃ§Ã£o
- **Recall CrÃ­tico**: NÃ£o perder casos de diabetes Ã© importante

#### â¡ï¸ PrÃ³ximos Passos

ApÃ³s completar este notebook, vocÃª pode revisar o relatÃ³rio tÃ©cnico ou experimentar diferentes hiperparÃ¢metros.

---

## ğŸ”¬ Detalhes TÃ©cnicos

Esta seÃ§Ã£o apresenta os detalhes tÃ©cnicos do projeto, incluindo estratÃ©gias de prÃ©-processamento, justificativas dos modelos e discussÃµes sobre mÃ©tricas.

### EstratÃ©gias de PrÃ©-processamento

#### Dados Tabulares

**1. Limpeza de Dados**

**CÃ¢ncer de Mama:**

- **RemoÃ§Ã£o de colunas nÃ£o relevantes**:

  - `id`: Identificador Ãºnico (nÃ£o preditivo)
  - `Unnamed: 32`: Coluna vazia/duplicada

- **Tratamento de valores ausentes e infinitos**:

  - SubstituiÃ§Ã£o de valores infinitos por NaN
  - Preenchimento de NaN com a mÃ©dia da coluna (se necessÃ¡rio)
  - No dataset utilizado, nÃ£o foram encontrados valores ausentes

- **SeleÃ§Ã£o de features**:
  - UtilizaÃ§Ã£o apenas de colunas numÃ©ricas
  - RemoÃ§Ã£o de colunas identificadoras

**Diabetes:**

- **IdentificaÃ§Ã£o de valores zero como ausentes**:

  - Glucose, BloodPressure, SkinThickness, Insulin, BMI tÃªm zeros que representam dados ausentes
  - Zeros sÃ£o substituÃ­dos por NaN

- **ImputaÃ§Ã£o de valores ausentes**:

  - Uso de `SimpleImputer` com estratÃ©gia 'mean'
  - Preenchimento com mÃ©dia da coluna calculada no treino

- **SeleÃ§Ã£o de features**:
  - UtilizaÃ§Ã£o de todas as 8 features clÃ­nicas
  - Outcome como variÃ¡vel alvo

**2. NormalizaÃ§Ã£o**

- **StandardScaler**: NormalizaÃ§Ã£o das features para mÃ©dia zero e desvio padrÃ£o unitÃ¡rio
- **Justificativa**:
  - Diferentes features tÃªm escalas distintas (ex: Ã¡rea vs. textura, glicose vs. idade)
  - Modelos lineares (RegressÃ£o LogÃ­stica) sÃ£o sensÃ­veis Ã  escala
  - Essencial para KNN (algoritmo baseado em distÃ¢ncia)
  - Facilita convergÃªncia e melhora desempenho

**3. DivisÃ£o dos Dados**

- **EstratÃ©gia**: DivisÃ£o estratificada em trÃªs conjuntos
  - **Treino (60%)**: 341 amostras - Para treinar os modelos
  - **ValidaÃ§Ã£o (20%)**: 114 amostras - Para ajuste de hiperparÃ¢metros e seleÃ§Ã£o de modelo
  - **Teste (20%)**: 114 amostras - Para avaliaÃ§Ã£o final e relatÃ³rio de desempenho
- **EstratificaÃ§Ã£o**: MantÃ©m a proporÃ§Ã£o de classes em cada conjunto
- **Random State**: 42 (para reprodutibilidade)

#### Dados de Imagens

**1. Redimensionamento e NormalizaÃ§Ã£o**

- **Redimensionamento**: Todas as imagens foram redimensionadas para tamanhos fixos
  - Pneumonia: 224x224 pixels (RGB)
  - CÃ¢ncer de Mama: 256x256 pixels (escala de cinza)
- **NormalizaÃ§Ã£o**: Pixels normalizados para o intervalo [0, 1] dividindo por 255
- **ConversÃ£o de Cores**:
  - Pneumonia: Mantido RGB (3 canais)
  - CÃ¢ncer de Mama: Convertido para escala de cinza (1 canal)

**2. Data Augmentation**

Para aumentar a robustez do modelo e reduzir overfitting, foram aplicadas tÃ©cnicas de data augmentation no conjunto de treino:

- **RotaÃ§Ã£o**: Â±30 graus
- **Deslocamento**: Horizontal e vertical (Â±15%)
- **Zoom**: Â±20%
- **Flip Horizontal**: Espelhamento aleatÃ³rio
- **Flip Vertical**: Espelhamento vertical (para cÃ¢ncer de mama)
- **Brightness**: Ajuste de brilho [0.8, 1.2]
- **Shear**: Cisalhamento de Â±10%

**Justificativa**:

- Aumenta a diversidade do conjunto de treino
- Melhora generalizaÃ§Ã£o
- Simula variaÃ§Ãµes naturais em imagens mÃ©dicas (posicionamento, Ã¢ngulo, etc.)

**3. DivisÃ£o dos Dados**

- **Treino (60%)**: Para treinar o modelo
- **ValidaÃ§Ã£o (20%)**: Para ajuste de hiperparÃ¢metros e early stopping
- **Teste (20%)**: Para avaliaÃ§Ã£o final
- **EstratificaÃ§Ã£o**: MantÃ©m proporÃ§Ã£o de classes em cada conjunto

### Modelos Utilizados e Justificativa

#### Dados Tabulares

**1. RegressÃ£o LogÃ­stica**

**Justificativa**:

- Modelo linear interpretÃ¡vel e eficiente
- Funciona bem como baseline para comparaÃ§Ã£o
- RÃ¡pido para treinar e fazer prediÃ§Ãµes
- Boa performance em problemas de classificaÃ§Ã£o binÃ¡ria
- Probabilidades de saÃ­da sÃ£o calibradas

**ParÃ¢metros**:

- `solver='lbfgs'`: Algoritmo robusto para problemas pequenos/mÃ©dios
- `C=1.0`: RegularizaÃ§Ã£o L2 (inverso da forÃ§a de regularizaÃ§Ã£o)
- `max_iter=1000`: NÃºmero mÃ¡ximo de iteraÃ§Ãµes (definido no config.yaml)
- `random_state=42`: Reprodutibilidade

**Vantagens**:

- Interpretabilidade (coeficientes lineares)
- Baixa complexidade computacional
- Menor risco de overfitting

**Desvantagens**:

- Assume relaÃ§Ã£o linear entre features e target
- Pode nÃ£o capturar interaÃ§Ãµes complexas

**2. Random Forest**

**Justificativa**:

- Algoritmo de ensemble robusto e poderoso
- Capaz de capturar relaÃ§Ãµes nÃ£o-lineares
- Menos propenso a overfitting que Ã¡rvores individuais
- Fornece feature importance nativa
- Geralmente apresenta melhor desempenho que modelos lineares

**ParÃ¢metros**:

- `n_estimators=100`: NÃºmero de Ã¡rvores no ensemble (definido no config.yaml)
- `max_depth=10`: Profundidade mÃ¡xima das Ã¡rvores (controla complexidade)
- `random_state=42`: Reprodutibilidade

**Vantagens**:

- Alta capacidade de modelagem
- Robustez a outliers
- Feature importance integrada
- Boa performance geral

**Desvantagens**:

- Menos interpretÃ¡vel que modelos lineares
- Maior complexidade computacional
- Pode ser mais difÃ­cil de explicar para nÃ£o-especialistas

**3. K-Nearest Neighbors (KNN)**

**Justificativa**:

- Complementa os modelos anteriores (RegressÃ£o LogÃ­stica Ã© linear, Random Forest Ã© baseado em Ã¡rvores)
- NÃ£o paramÃ©trico, nÃ£o assume distribuiÃ§Ã£o dos dados
- Pode capturar padrÃµes nÃ£o-lineares
- Simples conceitualmente
- Funciona bem com normalizaÃ§Ã£o adequada

**ParÃ¢metros**:

- `n_neighbors=5`: NÃºmero de vizinhos a considerar (k) - definido no config.yaml
- `weights='uniform'`: Peso uniforme para todos os vizinhos
- `algorithm='auto'`: Algoritmo automÃ¡tico para encontrar vizinhos

**Vantagens**:

- Simples e intuitivo
- NÃ£o linear
- Pode ser muito eficaz com dados normalizados

**Desvantagens**:

- Computacionalmente caro para grandes datasets
- SensÃ­vel Ã  escala (StandardScaler Ã© essencial)
- Pode ser sensÃ­vel a features irrelevantes
- Lento para prediÃ§Ã£o em datasets grandes

**4. Pipeline de Processamento**

Todos os trÃªs modelos foram implementados em um pipeline que inclui:

1. **StandardScaler**: NormalizaÃ§Ã£o das features (essencial para RegressÃ£o LogÃ­stica e KNN)
2. **Modelo**: RegressÃ£o LogÃ­stica, Random Forest ou KNN

Isso garante que:

- Novos dados sejam prÃ©-processados da mesma forma
- O modelo salvo inclui todas as transformaÃ§Ãµes necessÃ¡rias

#### Dados de Imagens (CNNs)

**1. CNN para Pneumonia**

**Arquitetura**:

- **Input**: Imagens RGB 224x224x3
- **4 Blocos Convolucionais**:
  - Bloco 1: 32 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
  - Bloco 2: 64 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
  - Bloco 3: 128 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
  - Bloco 4: 128 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
- **Camadas Densas**:
  - Flatten
  - Dense(512) + BatchNorm + Dropout(0.5)
  - Dense(256) + BatchNorm + Dropout(0.5)
  - Dense(2, activation='softmax')

**Total de parÃ¢metros**: ~2-3 milhÃµes

**2. CNN para CÃ¢ncer de Mama**

**Arquitetura**:

- **Input**: Imagens em escala de cinza 256x256x1
- **5 Blocos Convolucionais**:
  - Bloco 1: 32 filtros 5x5 + BatchNorm + MaxPooling 2x2 + Dropout 0.1
  - Bloco 2: 64 filtros 5x5 + BatchNorm + MaxPooling 2x2 + Dropout 0.15
  - Bloco 3: 128 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.2
  - Bloco 4: 256 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
  - Bloco 5: 256 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
- **Global Average Pooling**: Reduz dimensÃµes e previne overfitting
- **Camadas Densas**: Similar Ã  CNN de pneumonia, com L2 regularization

**Justificativa da arquitetura mais profunda**:

- Mamografias podem requerer anÃ¡lise mais detalhada
- Mais camadas para capturar padrÃµes sutis de lesÃµes
- Global Average Pooling reduz parÃ¢metros e melhora generalizaÃ§Ã£o

**3. ConfiguraÃ§Ãµes de Treinamento**

- **Otimizador**: AdamW (com weight decay) ou Adam
- **Learning Rate**: 0.0001 (reduzido para treinamento mais estÃ¡vel)
- **Loss**: Categorical Crossentropy ou Focal Loss (para classes desbalanceadas)
- **MÃ©tricas**: Accuracy, Precision, Recall
- **Batch Size**: 32
- **Ã‰pocas**: 50 (com early stopping)
- **Early Stopping**: Patience=10, monitor='val_loss'
- **Model Checkpoint**: Salva melhor modelo baseado em val_loss e val_accuracy
- **ReduceLROnPlateau**: Reduz learning rate quando validaÃ§Ã£o estagna

**4. Callbacks**

1. **ModelCheckpoint**: Salva o melhor modelo durante treinamento
2. **EarlyStopping**: Para treinamento quando nÃ£o hÃ¡ melhoria
3. **ReduceLROnPlateau**: Ajusta learning rate dinamicamente

### Justificativa da Escolha das MÃ©tricas

Em problemas de diagnÃ³stico mÃ©dico, a escolha das mÃ©tricas de avaliaÃ§Ã£o Ã© crÃ­tica e deve considerar o contexto clÃ­nico e os custos associados a diferentes tipos de erro. Neste projeto, utilizamos quatro mÃ©tricas principais: **Accuracy**, **Precision**, **Recall** e **F1-Score**. A seguir, justificamos a escolha de cada uma:

#### Por que Accuracy nÃ£o Ã© suficiente?

A **Accuracy** (AcurÃ¡cia) mede a proporÃ§Ã£o de prediÃ§Ãµes corretas sobre o total. Embora seja uma mÃ©trica intuitiva, ela pode ser enganosa em problemas mÃ©dicos, especialmente quando hÃ¡ desbalanceamento de classes:

- **LimitaÃ§Ã£o**: Em um dataset com 62% de casos benignos e 38% malignos, um modelo que sempre prediz "benigno" teria 62% de accuracy, mas seria completamente inÃºtil para detectar cÃ¢ncer
- **Uso adequado**: A accuracy Ã© Ãºtil como mÃ©trica geral, mas nÃ£o deve ser a Ãºnica considerada em diagnÃ³stico mÃ©dico

#### Por que Recall Ã© crÃ­tico em diagnÃ³stico mÃ©dico?

O **Recall** (Sensibilidade) mede a proporÃ§Ã£o de casos positivos (malignos) que foram corretamente identificados:

- **ImportÃ¢ncia clÃ­nica**: Em diagnÃ³stico de cÃ¢ncer, **falsos negativos sÃ£o extremamente perigosos** - um caso maligno nÃ£o detectado pode resultar em progressÃ£o da doenÃ§a e pior prognÃ³stico
- **InterpretaÃ§Ã£o**: Um Recall de 92.86% significa que o modelo detecta 92.86% dos casos malignos, mas ainda falha em detectar 7.14% (3 casos no nosso conjunto de teste)
- **Custo do erro**: O custo de nÃ£o detectar um cÃ¢ncer maligno Ã© muito maior que o custo de um falso positivo (que pode ser resolvido com exames adicionais)

#### Por que Precision Ã© importante?

A **Precision** (PrecisÃ£o) mede a proporÃ§Ã£o de prediÃ§Ãµes positivas que sÃ£o realmente corretas:

- **ImportÃ¢ncia clÃ­nica**: **Falsos positivos** podem causar ansiedade desnecessÃ¡ria, exames invasivos adicionais (biÃ³psias) e custos mÃ©dicos
- **InterpretaÃ§Ã£o**: Uma Precision de 100% (Random Forest) significa que quando o modelo prediz "maligno", estÃ¡ sempre correto - nÃ£o hÃ¡ falsos alarmes
- **Balanceamento**: Alta precision reduz o nÃºmero de biÃ³psias desnecessÃ¡rias, mas nÃ£o deve comprometer o recall

#### Por que F1-Score Ã© uma mÃ©trica balanceada?

O **F1-Score** Ã© a mÃ©dia harmÃ´nica entre Precision e Recall:

- **Vantagem**: Balanceia a importÃ¢ncia de detectar casos positivos (Recall) e evitar falsos alarmes (Precision)
- **Uso**: Ãštil quando precisamos de uma Ãºnica mÃ©trica que considere ambos os aspectos
- **LimitaÃ§Ã£o**: Assume que Precision e Recall tÃªm igual importÃ¢ncia, o que pode nÃ£o ser verdade em todos os contextos mÃ©dicos

#### ConsideraÃ§Ãµes para o Problema de CÃ¢ncer de Mama

Para diagnÃ³stico de cÃ¢ncer de mama, a hierarquia de importÃ¢ncia das mÃ©tricas Ã©:

1. **Recall (mais crÃ­tico)**: NÃ£o perder casos malignos Ã© a prioridade mÃ¡xima
2. **Precision (importante)**: Evitar alarmes falsos reduz ansiedade e custos
3. **F1-Score**: Fornece uma visÃ£o balanceada do desempenho geral
4. **Accuracy**: Ãštil como mÃ©trica geral, mas nÃ£o suficiente isoladamente

**ConclusÃ£o**: A combinaÃ§Ã£o dessas mÃ©tricas permite uma avaliaÃ§Ã£o completa do modelo, considerando tanto a capacidade de detectar casos crÃ­ticos quanto a precisÃ£o das prediÃ§Ãµes positivas. Em um contexto clÃ­nico real, mÃ©dicos podem ajustar o threshold de decisÃ£o baseado na importÃ¢ncia relativa de Recall vs Precision para cada paciente especÃ­fico.

### Resultados e InterpretaÃ§Ã£o

#### Dados Tabulares

**Desempenho dos Modelos - CÃ¢ncer de Mama**

**RegressÃ£o LogÃ­stica**:

- **Accuracy (Teste)**: ~96.5%
- **Precision (M)**: ~97.7%
- **Recall (M)**: ~92.9%
- **F1-Score (M)**: ~95.2%

**Random Forest**:

- **Accuracy (Teste)**: ~97.4%
- **Precision (M)**: ~100.0%
- **Recall (M)**: ~92.9%
- **F1-Score (M)**: ~96.3%

**KNN**:

- **Accuracy (Teste)**: ~93.0%
- **Precision (M)**: ~94.0%
- **Recall (M)**: ~88.0%
- **F1-Score (M)**: ~91.0%

**AnÃ¡lise Comparativa**:
O **Random Forest** apresentou o melhor desempenho geral, seguido por RegressÃ£o LogÃ­stica e KNN. Todos os trÃªs modelos apresentam desempenho excelente (>90% accuracy).

**Desempenho dos Modelos - Diabetes**

**RegressÃ£o LogÃ­stica**:

- **Accuracy (Teste)**: ~75-80%
- **Precision (1)**: ~70-75%
- **Recall (1)**: ~60-70%
- **F1-Score (1)**: ~65-72%

**Random Forest**:

- **Accuracy (Teste)**: ~78-82%
- **Precision (1)**: ~75-80%
- **Recall (1)**: ~65-75%
- **F1-Score (1)**: ~70-77%

**KNN**:

- **Accuracy (Teste)**: ~75-78%
- **Precision (1)**: ~72-77%
- **Recall (1)**: ~60-68%
- **F1-Score (1)**: ~65-72%

**AnÃ¡lise Comparativa**:
O **Random Forest** geralmente apresenta o melhor desempenho. O desempenho Ã© menor que no dataset de cÃ¢ncer de mama, o que Ã© esperado devido Ã  menor quantidade de features e complexidade do problema.

**Matriz de ConfusÃ£o (Random Forest)**:

```
                Predito
              B      M
Real    B    72     0
        M     3    39
```

- **Verdadeiros Negativos (TN)**: 72
- **Falsos Positivos (FP)**: 0
- **Falsos Negativos (FN)**: 3
- **Verdadeiros Positivos (TP)**: 39

**AnÃ¡lise**:

- Nenhum falso positivo: Todos os casos benignos foram corretamente identificados
- 3 falsos negativos: 3 casos malignos foram classificados como benignos
- **Impacto clÃ­nico**: Falsos negativos sÃ£o mais crÃ­ticos (caso maligno nÃ£o detectado)

**Feature Importance**:
As features mais importantes identificadas pelo Random Forest foram:

1. `concave points_worst` - Pontos cÃ´ncavos (pior valor)
2. `perimeter_worst` - PerÃ­metro (pior valor)
3. `concave points_mean` - Pontos cÃ´ncavos (mÃ©dia)
4. `radius_worst` - Raio (pior valor)
5. `area_worst` - Ãrea (pior valor)

**InterpretaÃ§Ã£o**: CaracterÃ­sticas relacionadas a concavidade e tamanho (perÃ­metro, raio, Ã¡rea) sÃ£o as mais preditivas, especialmente os valores "worst" (piores), que representam as caracterÃ­sticas mais extremas encontradas.

**AnÃ¡lise SHAP**:
A anÃ¡lise SHAP (SHapley Additive exPlanations) fornece interpretabilidade adicional:

**Insights Globais**:

- Confirma a importÃ¢ncia das features identificadas pela feature importance
- Mostra que valores altos de caracterÃ­sticas como `concave points_worst` e `perimeter_worst` aumentam a probabilidade de diagnÃ³stico maligno
- Valores baixos dessas caracterÃ­sticas indicam diagnÃ³stico benigno

**InterpretaÃ§Ã£o Local**:

- Permite entender por que cada prediÃ§Ã£o especÃ­fica foi feita
- Ãštil para explicar decisÃµes do modelo a mÃ©dicos e pacientes
- Mostra a contribuiÃ§Ã£o individual de cada feature para cada caso

#### Dados de Imagens

**MÃ©tricas de AvaliaÃ§Ã£o**:
Ambos os modelos de CNN foram avaliados usando:

- **Accuracy**: Taxa de acerto geral
- **Precision**: PrecisÃ£o por classe
- **Recall**: Sensibilidade por classe
- **F1-Score**: MÃ©dia harmÃ´nica de precision e recall
- **ROC-AUC**: Ãrea sob a curva ROC
- **Matriz de ConfusÃ£o**: VisualizaÃ§Ã£o de erros

**Interpretabilidade: Grad-CAM**:
**Grad-CAM (Gradient-weighted Class Activation Mapping)** foi implementado para visualizar as regiÃµes da imagem que mais influenciam a prediÃ§Ã£o do modelo.

**Como funciona**:

1. Calcula gradientes da classe predita em relaÃ§Ã£o Ã  Ãºltima camada convolucional
2. Cria um heatmap mostrando regiÃµes importantes
3. SuperpÃµe o heatmap na imagem original

**BenefÃ­cios**:

- **TransparÃªncia**: Mostra o que o modelo estÃ¡ "vendo"
- **ValidaÃ§Ã£o**: Permite verificar se o modelo foca em regiÃµes clinicamente relevantes
- **Debugging**: Identifica se o modelo estÃ¡ aprendendo padrÃµes corretos ou artefatos
- **ConfianÃ§a**: Ajuda mÃ©dicos a confiar nas prediÃ§Ãµes do modelo

**AplicaÃ§Ã£o**:

- VisualizaÃ§Ã£o de regiÃµes de atenÃ§Ã£o para casos de pneumonia
- IdentificaÃ§Ã£o de lesÃµes suspeitas em mamografias
- AnÃ¡lise de casos corretos e incorretos

### DiscussÃ£o CrÃ­tica e LimitaÃ§Ãµes

#### LimitaÃ§Ãµes Identificadas

**1. Dataset Limitado**:

- Apenas ~570 amostras podem limitar generalizaÃ§Ã£o
- Dataset especÃ­fico de cÃ¢ncer de mama
- PossÃ­vel viÃ©s geogrÃ¡fico/temporal

**2. Features DisponÃ­veis**:

- Apenas caracterÃ­sticas numÃ©ricas de exames
- NÃ£o considera histÃ³rico mÃ©dico, genÃ©tica ou estilo de vida
- Pode nÃ£o capturar todas as interaÃ§Ãµes relevantes

**3. Desbalanceamento de Classes**:

- Classe benigna tem mais amostras que maligna
- Apesar da estratificaÃ§Ã£o, pode impactar casos raros

**4. GeneralizaÃ§Ã£o**:

- Modelo treinado em dados histÃ³ricos
- NÃ£o testado em diferentes populaÃ§Ãµes
- ValidaÃ§Ã£o externa necessÃ¡ria

**5. Interpretabilidade**:

- Random Forest Ã© mais complexo que modelos lineares
- SHAP ajuda, mas requer conhecimento tÃ©cnico

#### Viabilidade de Uso PrÃ¡tico

**Pontos Positivos**:

- Alta acurÃ¡cia (>97%) sugere potencial para triagem inicial
- Modelo rÃ¡pido e eficiente
- Pode auxiliar na priorizaÃ§Ã£o de casos
- Interpretabilidade via SHAP e Grad-CAM

**ConsideraÃ§Ãµes Importantes**:

- **NÃƒO substitui o diagnÃ³stico mÃ©dico** - deve ser usado apenas como ferramenta de apoio
- Requer validaÃ§Ã£o clÃ­nica extensiva
- Necessita integraÃ§Ã£o com sistemas hospitalares
- Treinamento de equipe mÃ©dica necessÃ¡rio
- Monitoramento contÃ­nuo essencial

**Casos de Uso Sugeridos**:

- Triagem inicial para priorizaÃ§Ã£o
- Segunda opiniÃ£o para validaÃ§Ã£o
- EducaÃ§Ã£o mÃ©dica
- Pesquisa e identificaÃ§Ã£o de padrÃµes
- Controle de qualidade

**LimitaÃ§Ãµes para Uso ClÃ­nico**:

- NÃ£o deve ser Ãºnico critÃ©rio para diagnÃ³stico
- NÃ£o considera contexto clÃ­nico completo
- Pode gerar falsos positivos/negativos graves
- Requer aprovaÃ§Ã£o regulatÃ³ria
- Necessita auditoria e responsabilizaÃ§Ã£o

### ConsideraÃ§Ãµes Ã‰ticas e MÃ©dicas

**Privacidade e SeguranÃ§a**:

- Dados mÃ©dicos sensÃ­veis requerem proteÃ§Ã£o rigorosa (LGPD, HIPAA)
- AnonimizaÃ§Ã£o adequada necessÃ¡ria
- Criptografia e controle de acesso essenciais

**Responsabilidade e TransparÃªncia**:

- Responsabilidade final sempre do mÃ©dico
- TransparÃªncia sobre limitaÃ§Ãµes e taxa de erro
- DocumentaÃ§Ã£o clara do processo
- Possibilidade de apelaÃ§Ã£o/revisÃ£o

**ViÃ©s e Equidade**:

- Verificar viÃ©s contra grupos demogrÃ¡ficos
- Garantir representatividade do dataset
- Monitorar desempenho em subpopulaÃ§Ãµes
- Evitar discriminaÃ§Ã£o

**Impacto no Relacionamento MÃ©dico-Paciente**:

- IA nÃ£o deve substituir comunicaÃ§Ã£o mÃ©dico-paciente
- ExplicaÃ§Ãµes compreensÃ­veis para pacientes
- Respeitar autonomia do paciente
- Manter humanizaÃ§Ã£o do cuidado

**Qualidade e ValidaÃ§Ã£o**:

- ValidaÃ§Ã£o em mÃºltiplos centros
- ComparaÃ§Ã£o com padrÃ£o-ouro
- Estudos prospectivos necessÃ¡rios
- RevisÃ£o periÃ³dica do modelo

**PrincÃ­pio Fundamental**: O modelo deve sempre servir como **FERRAMENTA DE APOIO** Ã  decisÃ£o mÃ©dica, nunca como substituto do julgamento clÃ­nico profissional.

---

## ğŸ“ˆ Resultados Esperados

### Dados Tabulares

#### CÃ¢ncer de Mama

**RegressÃ£o LogÃ­stica**:

- **Accuracy**: ~96.5%
- **Precision (M)**: ~97.7%
- **Recall (M)**: ~92.9%
- **F1-Score (M)**: ~95.2%

**Random Forest (Melhor Modelo)**:

- **Accuracy**: ~97.4%
- **Precision (M)**: ~100.0%
- **Recall (M)**: ~92.9%
- **F1-Score (M)**: ~96.3%

**KNN**:

- **Accuracy**: ~93.0%
- **Precision (M)**: ~94.0%
- **Recall (M)**: ~88.0%
- **F1-Score (M)**: ~91.0%

#### Diabetes

**RegressÃ£o LogÃ­stica**:

- **Accuracy**: ~75-80%
- **Precision (1)**: ~70-75%
- **Recall (1)**: ~60-70%
- **F1-Score (1)**: ~65-72%

**Random Forest (Melhor Modelo)**:

- **Accuracy**: ~78-82%
- **Precision (1)**: ~75-80%
- **Recall (1)**: ~65-75%
- **F1-Score (1)**: ~70-77%

**KNN**:

- **Accuracy**: ~75-78%
- **Precision (1)**: ~72-77%
- **Recall (1)**: ~60-68%
- **F1-Score (1)**: ~65-72%

### ClassificaÃ§Ã£o de Imagens (CNNs)

#### Pneumonia em Raio-X

- **Modelo**: CNN construÃ­da do zero
- **Arquitetura**: 4 blocos convolucionais + camadas densas
- **Input**: Imagens RGB 224x224
- **MÃ©tricas Esperadas**: Accuracy > 80% (benchmark para CNNs simples)

#### CÃ¢ncer de Mama em Mamografias

- **Modelo**: CNN adaptada para escala de cinza
- **Arquitetura**: 5 blocos convolucionais + camadas densas
- **Input**: Imagens em escala de cinza 256x256
- **MÃ©tricas Esperadas**: Accuracy > 80%

### Features Mais Importantes (Dados Tabulares)

#### CÃ¢ncer de Mama

As caracterÃ­sticas mais preditivas identificadas:

1. `concave points_worst` - Pontos cÃ´ncavos (pior valor)
2. `perimeter_worst` - PerÃ­metro (pior valor)
3. `concave points_mean` - Pontos cÃ´ncavos (mÃ©dia)
4. `radius_worst` - Raio (pior valor)
5. `area_worst` - Ãrea (pior valor)

#### Diabetes

As caracterÃ­sticas mais preditivas identificadas:

1. `Glucose` - ConcentraÃ§Ã£o de glicose no plasma (geralmente a mais importante)
2. `BMI` - Ãndice de massa corporal
3. `Age` - Idade
4. `DiabetesPedigreeFunction` - FunÃ§Ã£o de linhagem do diabetes
5. `Insulin` - Insulina sÃ©rica

---

## ğŸ” Interpretabilidade

### Dados Tabulares

1. **Feature Importance**: ImportÃ¢ncia global das features (Random Forest)
   - **CÃ¢ncer de Mama**: Features "worst" (concave points_worst, perimeter_worst) sÃ£o mais importantes
   - **Diabetes**: Glucose geralmente Ã© a feature mais importante, seguida por BMI e Age
2. **SHAP Values**:
   - Interpretabilidade local (por prediÃ§Ã£o)
   - Interpretabilidade global (visÃ£o geral)
   - Waterfall plots para casos especÃ­ficos
   - Summary plots mostrando impacto de cada feature

### ClassificaÃ§Ã£o de Imagens

1. **Grad-CAM**: VisualizaÃ§Ã£o das regiÃµes da imagem que mais influenciam a prediÃ§Ã£o
   - Heatmaps sobrepostos nas imagens
   - AnÃ¡lise de casos corretos e incorretos
   - IdentificaÃ§Ã£o de padrÃµes aprendidos pelo modelo

---

## âš ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes

### LimitaÃ§Ãµes TÃ©cnicas

- Dataset limitado (~570 amostras)
- Apenas caracterÃ­sticas numÃ©ricas de exames
- NÃ£o considera histÃ³rico mÃ©dico completo
- PossÃ­vel viÃ©s geogrÃ¡fico/temporal

### ConsideraÃ§Ãµes para Uso ClÃ­nico

- **NÃƒO substitui o diagnÃ³stico mÃ©dico**
- Requer validaÃ§Ã£o clÃ­nica extensiva
- Necessita aprovaÃ§Ã£o regulatÃ³ria
- Monitoramento contÃ­nuo essencial
- TransparÃªncia e responsabilidade Ã©tica

Para mais detalhes, consulte a seÃ§Ã£o de **DiscussÃ£o CrÃ­tica** no notebook `02_tabular_modelagem.ipynb` e o `relatorio_tecnico.md`.

---

## ğŸ³ Docker (Opcional)

Para executar em container Docker:

```bash
# Construir imagem
docker build -t tech-challenge .

# Executar container
docker run -it -p 8888:8888 tech-challenge
```

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **RelatÃ³rio TÃ©cnico**: `relatorio_tecnico.md` - DocumentaÃ§Ã£o completa do projeto
- **Notebooks**: ContÃªm anÃ¡lise detalhada e comentÃ¡rios explicativos
- **CÃ³digo Fonte**: FunÃ§Ãµes modulares em `src/tabular/` e `src/vision/`

---

## ğŸ‘¥ ContribuiÃ§Ã£o

Este projeto foi desenvolvido como parte do Tech Challenge Fase 1.

---

## ğŸ“„ LicenÃ§a

Consulte o arquivo `LICENSE` para mais informaÃ§Ãµes.

---

## ğŸ“ Contato

Para dÃºvidas ou sugestÃµes, abra uma issue no repositÃ³rio.
