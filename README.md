# Tech Challenge - Fase 1

## Sistema Inteligente de Suporte ao Diagn√≥stico M√©dico

Este projeto implementa modelos de machine learning para **classifica√ß√£o de exames m√©dicos**, utilizando dados estruturados e imagens para auxiliar profissionais de sa√∫de na tomada de decis√£o cl√≠nica.

> ‚ö†Ô∏è **IMPORTANTE**: Este sistema n√£o substitui o m√©dico. Ele atua como ferramenta de apoio e triagem. A decis√£o final sempre deve ser do profissional m√©dico qualificado.

---

## üìë √çndice

1. [Problema Abordado](#-problema-abordado)
2. [Datasets Utilizados](#-datasets-utilizados)
3. [Estrutura do Projeto](#-estrutura-do-projeto)
4. [Instala√ß√£o e Configura√ß√£o](#-instala√ß√£o-e-configura√ß√£o)
5. [üìö Guia Passo a Passo Completo](#-guia-passo-a-passo-completo)
   - [Notebook 01: Explora√ß√£o de Dados Tabulares](#notebook-01-explora√ß√£o-de-dados-tabulares)
   - [Notebook 02: Modelagem de Dados Tabulares](#notebook-02-modelagem-de-dados-tabulares)
   - [Notebook 03: Explora√ß√£o de Imagens de Pneumonia](#notebook-03-explora√ß√£o-de-imagens-de-pneumonia)
   - [Notebook 04: Modelagem CNN para Pneumonia](#notebook-04-modelagem-cnn-para-pneumonia)
   - [Notebook 05: Explora√ß√£o de Mamografias](#notebook-05-explora√ß√£o-de-mamografias)
   - [Notebook 06: Modelagem CNN para C√¢ncer de Mama](#notebook-06-modelagem-cnn-para-c√¢ncer-de-mama)
6. [üî¨ Detalhes T√©cnicos](#-detalhes-t√©cnicos)
7. [üìà Resultados Esperados](#-resultados-esperados)
8. [üîç Interpretabilidade](#-interpretabilidade)
9. [‚ö†Ô∏è Limita√ß√µes e Considera√ß√µes](#Ô∏è-limita√ß√µes-e-considera√ß√µes)
10. [üê≥ Docker](#-docker)
11. [üìö Documenta√ß√£o Adicional](#-documenta√ß√£o-adicional)

---

## üìå Problema Abordado

Este projeto aborda dois tipos de classifica√ß√£o m√©dica:

### 1. Classifica√ß√£o de C√¢ncer de Mama (Dados Tabulares)

Classifica√ß√£o bin√°ria para diagn√≥stico de **c√¢ncer de mama** em duas categorias:

- **B (Benigno)**: Tumor benigno
- **M (Maligno)**: Tumor maligno

O modelo utiliza caracter√≠sticas cl√≠nicas num√©ricas obtidas de exames m√©dicos (raio, textura, per√≠metro, √°rea, suavidade, compacta√ß√£o, concavidade, etc.) para fazer predi√ß√µes.

### 2. Classifica√ß√£o de Imagens M√©dicas (CNNs)

#### 2.1 Pneumonia em Raio-X

Classifica√ß√£o bin√°ria de imagens de raio-X de t√≥rax:

- **Normal**: Sem sinais de pneumonia
- **Pneumonia**: Com sinais de pneumonia

#### 2.2 C√¢ncer de Mama em Mamografias

Classifica√ß√£o bin√°ria de imagens de mamografia:

- **Benigno**: Les√µes benignas
- **Maligno**: Les√µes malignas (c√¢ncer)

---

## üß™ Datasets Utilizados

### Dados Tabulares

- **Dataset**: Wisconsin Breast Cancer Dataset
- **Fonte**: UCI Machine Learning Repository
- **Tamanho**: 569 amostras
- **Features**: 30 caracter√≠sticas num√©ricas
- **Distribui√ß√£o**: ~62% benigno, ~38% maligno
- **Localiza√ß√£o**: `data/tabular/breast-cancer.csv`

### Dados de Imagens

#### Pneumonia em Raio-X

- **Dataset**: Chest X-Ray Images (Pneumonia)
- **Fonte**: Kaggle (paultimothymooney/chest-xray-pneumonia)
- **Tipo**: Imagens de raio-X de t√≥rax
- **Classes**: Normal, Pneumonia
- **Download**: Autom√°tico via kagglehub

#### C√¢ncer de Mama (CBIS-DDSM)

- **Dataset**: CBIS-DDSM (Curated Breast Imaging Subset of DDSM)
- **Fonte**: Kaggle (awsaf49/cbis-ddsm-breast-cancer-image-dataset)
- **Tipo**: Imagens de mamografia
- **Classes**: Benigno, Maligno
- **Download**: Autom√°tico via kagglehub

### Caracter√≠sticas do Dataset Tabular

O dataset cont√©m medidas computadas a partir de imagens digitalizadas de aspirados por agulha fina (FNA) de massas mam√°rias. As features descrevem caracter√≠sticas do n√∫cleo celular, incluindo:

- **Raio**: M√©dia das dist√¢ncias do centro aos pontos do per√≠metro
- **Textura**: Desvio padr√£o dos valores de escala de cinza
- **Per√≠metro**: Per√≠metro do n√∫cleo
- **√Årea**: √Årea do n√∫cleo
- **Suavidade**: Varia√ß√£o local nos comprimentos dos raios
- **Compacta√ß√£o**: Per√≠metro¬≤ / √°rea - 1.0
- **Concavidade**: Severidade das por√ß√µes c√¥ncavas do contorno
- **Pontos c√¥ncavos**: N√∫mero de por√ß√µes c√¥ncavas do contorno
- **Simetria**: Medida de simetria
- **Dimens√£o fractal**: Aproxima√ß√£o "coastline" - 1

Cada feature possui tr√™s vers√µes: `_mean` (m√©dia), `_se` (erro padr√£o), `_worst` (pior valor).

---

## üèó Estrutura do Projeto

```
tech-challenge-8IADT/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ tabular/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ breast-cancer.csv          # Dataset tabular
‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îÇ       ‚îú‚îÄ‚îÄ pneumonia/                  # Dataset de pneumonia (baixado)
‚îÇ       ‚îî‚îÄ‚îÄ breast_cancer/             # Dataset de c√¢ncer de mama (baixado)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_tabular_exploracao.ipynb   # EDA dados tabulares
‚îÇ   ‚îú‚îÄ‚îÄ 02_tabular_modelagem.ipynb    # Modelagem dados tabulares
‚îÇ   ‚îú‚îÄ‚îÄ 03_vision_pneumonia_exploracao.ipynb   # EDA pneumonia
‚îÇ   ‚îú‚îÄ‚îÄ 04_vision_pneumonia_modelagem.ipynb    # CNN pneumonia
‚îÇ   ‚îú‚îÄ‚îÄ 05_vision_breast_exploracao.ipynb      # EDA c√¢ncer de mama
‚îÇ   ‚îî‚îÄ‚îÄ 06_vision_breast_modelagem.ipynb       # CNN c√¢ncer de mama
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ tabular/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processing.py              # Pr√©-processamento tabular
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py                # Avalia√ß√£o tabular
‚îÇ   ‚îî‚îÄ‚îÄ vision/
‚îÇ       ‚îú‚îÄ‚îÄ data_loader.py             # Carregamento de imagens
‚îÇ       ‚îú‚îÄ‚îÄ preprocessing.py           # Pr√©-processamento de imagens
‚îÇ       ‚îú‚îÄ‚îÄ models.py                  # Arquiteturas CNN
‚îÇ       ‚îî‚îÄ‚îÄ evaluation.py              # Avalia√ß√£o e Grad-CAM
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ maternal_risk_model.pkl       # Modelo tabular
‚îÇ   ‚îú‚îÄ‚îÄ pneumonia_cnn_model.h5        # CNN pneumonia
‚îÇ   ‚îî‚îÄ‚îÄ breast_cancer_cnn_model.h5     # CNN c√¢ncer de mama
‚îú‚îÄ‚îÄ config.yaml                        # Configura√ß√µes
‚îú‚îÄ‚îÄ requirements.txt                   # Depend√™ncias
‚îú‚îÄ‚îÄ Dockerfile                         # Containeriza√ß√£o
‚îú‚îÄ‚îÄ README.md                          # Este arquivo
‚îî‚îÄ‚îÄ relatorio_tecnico.md               # Relat√≥rio t√©cnico
```

---

## üöÄ Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- Jupyter Notebook ou JupyterLab (para executar os notebooks)

### Passo 1: Clonar o Reposit√≥rio

```bash
git clone <url-do-repositorio>
cd tech-challenge-8IADT
```

### Passo 2: Instalar Depend√™ncias

```bash
pip3 install -r requirements.txt
```

**Nota**: Se voc√™ receber um erro "command not found: pip", use `pip3` em vez de `pip`. No macOS, o comando geralmente √© `pip3`.

**Principais depend√™ncias**:

- `pandas`: Manipula√ß√£o de dados
- `numpy`: Computa√ß√£o num√©rica
- `scikit-learn`: Machine learning
- `tensorflow`: Deep learning e CNNs
- `matplotlib` e `seaborn`: Visualiza√ß√£o
- `shap`: Interpretabilidade de modelos
- `kagglehub`: Download de datasets do Kaggle
- `pillow`, `scikit-image`: Processamento de imagens
- `jupyter`: Notebooks interativos

### Passo 3: Verificar Datasets

- **Dados Tabulares**: Certifique-se de que o arquivo `data/tabular/breast-cancer.csv` est√° presente
- **Dados de Imagens**: Os datasets ser√£o baixados automaticamente ao executar os notebooks de explora√ß√£o (03 e 05)

### Passo 4: Iniciar Jupyter

```bash
jupyter notebook
```

Ou, se preferir JupyterLab:

```bash
jupyter lab
```

### Passo 5: Instalar Depend√™ncias de Desenvolvimento (Opcional)

Para executar os testes do projeto:

```bash
pip3 install -r requirements-dev.txt
```

**Nota**: Se voc√™ receber um erro "command not found: pip", use `pip3` em vez de `pip`.

---

## üß™ Executando Testes

O projeto inclui uma su√≠te completa de testes seguindo as melhores pr√°ticas de mercado.

### Executar Todos os Testes

```bash
pytest
```

### Executar Testes com Cobertura

```bash
pytest --cov=src --cov-report=html
```

Isso gerar√° um relat√≥rio HTML em `htmlcov/index.html` mostrando a cobertura de c√≥digo.

### Executar Apenas Testes Unit√°rios

```bash
pytest tests/unit -m unit
```

### Executar Apenas Testes de Integra√ß√£o

```bash
pytest tests/integration -m integration
```

### Executar Testes Espec√≠ficos

```bash
# Testar um m√≥dulo espec√≠fico
pytest tests/unit/test_tabular_processing.py

# Testar uma classe espec√≠fica
pytest tests/unit/test_tabular_processing.py::TestSplitData

# Testar uma fun√ß√£o espec√≠fica
pytest tests/unit/test_tabular_processing.py::TestSplitData::test_split_data_basic
```

### Ver Cobertura de C√≥digo

```bash
# Cobertura no terminal
pytest --cov=src --cov-report=term-missing

# Cobertura em HTML (abre no navegador)
pytest --cov=src --cov-report=html && open htmlcov/index.html
```

### Estrutura de Testes

```
tests/
‚îú‚îÄ‚îÄ conftest.py              # Fixtures compartilhadas
‚îú‚îÄ‚îÄ unit/                     # Testes unit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ test_tabular_processing.py
‚îÇ   ‚îú‚îÄ‚îÄ test_tabular_evaluate.py
‚îÇ   ‚îú‚îÄ‚îÄ test_vision_data_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ test_vision_preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ test_vision_models.py
‚îÇ   ‚îî‚îÄ‚îÄ test_vision_evaluation.py
‚îú‚îÄ‚îÄ integration/             # Testes de integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ test_tabular_pipeline.py
‚îÇ   ‚îî‚îÄ‚îÄ test_vision_pipeline.py
‚îî‚îÄ‚îÄ fixtures/                # Dados sint√©ticos para testes
    ‚îú‚îÄ‚îÄ sample_data.py
    ‚îî‚îÄ‚îÄ sample_images.py
```

### Cobertura de Testes

Os testes cobrem:
- ‚úÖ Todas as fun√ß√µes dos m√≥dulos `src/tabular/`
- ‚úÖ Todas as fun√ß√µes dos m√≥dulos `src/vision/`
- ‚úÖ Edge cases e tratamento de erros
- ‚úÖ Valida√ß√£o de dados de entrada
- ‚úÖ Testes de integra√ß√£o para pipelines completos
- ‚úÖ Mocks para opera√ß√µes custosas (downloads, treinamento)

**Meta de cobertura**: 80% ou mais

---

## üìö Guia Passo a Passo Completo

Este guia explica detalhadamente cada notebook do projeto, o que ele faz, o que voc√™ ver√° ao execut√°-lo e como interpretar os resultados.

### Notebook 01: Explora√ß√£o de Dados Tabulares

#### üéØ Objetivo

Este notebook realiza uma **an√°lise explorat√≥ria de dados (EDA)** do dataset de c√¢ncer de mama. Ele examina as caracter√≠sticas dos dados, identifica padr√µes, verifica a qualidade dos dados e prepara o terreno para a modelagem.

#### üìã Pr√©-requisitos

- Python 3.8+ instalado
- Depend√™ncias do `requirements.txt` instaladas
- Arquivo `data/tabular/breast-cancer.csv` presente no projeto

#### üìù Passo a Passo

**Passo 1: Carregamento dos Dados**
- **O que fazer**: Execute a primeira c√©lula que importa as bibliotecas e carrega o dataset
- **O que voc√™ ver√°**: Uma tabela mostrando as primeiras 5 linhas do dataset com todas as colunas
- **O que significa**: Voc√™ est√° visualizando uma amostra dos dados. Cada linha representa um paciente e cada coluna uma caracter√≠stica medida (raio, textura, per√≠metro, etc.)

**Passo 2: An√°lise Descritiva**
- **O que fazer**: Execute as c√©lulas que mostram `df.info()` e `df.describe()`
- **O que voc√™ ver√°**: 
  - `df.info()`: Lista de todas as colunas, tipos de dados e quantidade de valores n√£o nulos
  - `df.describe()`: Estat√≠sticas descritivas (m√©dia, desvio padr√£o, m√≠nimo, m√°ximo, quartis) para cada coluna num√©rica
- **O que significa**: 
  - `info()` confirma que n√£o h√° valores faltantes (todos os 569 registros t√™m valores)
  - `describe()` mostra a distribui√ß√£o dos valores. Por exemplo, se a m√©dia de `radius_mean` √© 14.1, isso indica o tamanho m√©dio dos n√∫cleos celulares

**Passo 3: An√°lise da Vari√°vel Alvo**
- **O que fazer**: Execute as c√©lulas que visualizam a distribui√ß√£o da vari√°vel `diagnosis`
- **O que voc√™ ver√°**: 
  - Um gr√°fico de barras mostrando quantos casos s√£o Benignos (B) e quantos s√£o Malignos (M)
  - Um gr√°fico de pizza (pie chart) mostrando as propor√ß√µes
  - Estat√≠sticas de contagem
- **O que significa**: 
  - Voc√™ ver√° aproximadamente 357 casos Benignos (62.7%) e 212 casos Malignos (37.3%)
  - Isso indica um **desbalanceamento moderado** das classes, o que √© importante considerar na modelagem

**Passo 4: An√°lise de Correla√ß√£o**
- **O que fazer**: Execute as c√©lulas que criam a matriz de correla√ß√£o
- **O que voc√™ ver√°**: 
  - Um mapa de calor (heatmap) colorido mostrando correla√ß√µes entre vari√°veis
  - Cores quentes (vermelho/laranja) indicam correla√ß√£o positiva forte
  - Cores frias (azul) indicam correla√ß√£o negativa
- **O que significa**: 
  - Vari√°veis altamente correlacionadas (ex: `radius_mean` e `perimeter_mean`) fornecem informa√ß√µes similares
  - Isso pode indicar redund√¢ncia, mas tamb√©m pode ser √∫til para o modelo

**Passo 5: Visualiza√ß√£o de Distribui√ß√µes**
- **O que fazer**: Execute as c√©lulas que criam histogramas e boxplots
- **O que voc√™ ver√°**: 
  - Histogramas mostrando a distribui√ß√£o de valores para diferentes features
  - Boxplots comparando a distribui√ß√£o entre classes Benignas e Malignas
- **O que significa**: 
  - Se voc√™ v√™ diferen√ßas claras nos boxplots entre B e M, essa feature √© provavelmente importante para classifica√ß√£o
  - Por exemplo, se `radius_worst` √© maior em casos Malignos, isso faz sentido clinicamente

#### üìä Sa√≠das Esperadas

1. **Tabela de dados**: Primeiras linhas do dataset
2. **Estat√≠sticas descritivas**: Tabela com m√©dias, desvios padr√£o, etc.
3. **Gr√°fico de distribui√ß√£o de classes**: Bar chart e pie chart mostrando ~62% Benigno, ~38% Maligno
4. **Matriz de correla√ß√£o**: Heatmap colorido mostrando rela√ß√µes entre vari√°veis
5. **Histogramas**: Distribui√ß√µes de features individuais
6. **Boxplots**: Compara√ß√£o de features entre classes B e M

#### üí° Interpreta√ß√£o dos Resultados

- **Qualidade dos dados**: Se n√£o h√° valores faltantes e os tipos de dados est√£o corretos, os dados est√£o prontos para modelagem
- **Desbalanceamento**: O dataset tem mais casos benignos que malignos. Isso √© normal, mas devemos usar estratifica√ß√£o na divis√£o dos dados
- **Features importantes**: Features que mostram diferen√ßas claras entre B e M nos boxplots s√£o candidatas a serem importantes para o modelo
- **Correla√ß√µes**: Features muito correlacionadas (ex: radius, perimeter, area) s√£o relacionadas, o que √© esperado

#### ‚û°Ô∏è Pr√≥ximos Passos

Ap√≥s completar este notebook, voc√™ est√° pronto para o **Notebook 02: Modelagem de Dados Tabulares**, onde os dados ser√£o usados para treinar modelos de machine learning.

---

### Notebook 02: Modelagem de Dados Tabulares

#### üéØ Objetivo

Este notebook treina e avalia modelos de machine learning para prever se um tumor √© benigno ou maligno com base nas caracter√≠sticas cl√≠nicas. Voc√™ ver√° dois modelos diferentes (Regress√£o Log√≠stica e Random Forest) sendo treinados, comparados e interpretados.

#### üìã Pr√©-requisitos

- Notebook 01 executado (para entender os dados)
- Dataset carregado e limpo
- Bibliotecas scikit-learn e SHAP instaladas

#### üìù Passo a Passo

**Passo 1: Prepara√ß√£o dos Dados**
- **O que fazer**: Execute as c√©lulas que separam features (X) da vari√°vel alvo (y) e dividem os dados
- **O que voc√™ ver√°**: 
  - Mensagens mostrando quantas features foram selecionadas (30)
  - Informa√ß√µes sobre a divis√£o: 341 amostras de treino, 114 de valida√ß√£o, 114 de teste
- **O que significa**: 
  - Os dados s√£o divididos em tr√™s conjuntos: **treino** (para aprender), **valida√ß√£o** (para ajustar) e **teste** (para avaliar final)
  - A divis√£o √© **estratificada**, mantendo a propor√ß√£o de classes em cada conjunto

**Passo 2: Treinamento do Modelo 1 - Regress√£o Log√≠stica**
- **O que fazer**: Execute as c√©lulas que criam e treinam o modelo de Regress√£o Log√≠stica
- **O que voc√™ ver√°**: 
  - Mensagem "Treinando Regress√£o Log√≠stica..."
  - Relat√≥rios de classifica√ß√£o mostrando m√©tricas para valida√ß√£o e teste
  - Tabelas com Precision, Recall, F1-Score para cada classe
- **O que significa**: 
  - **Precision**: Quando o modelo diz "Maligno", quantas vezes est√° correto (~97%)
  - **Recall**: Quantos casos malignos o modelo consegue detectar (~93%)
  - **F1-Score**: M√©dia balanceada entre Precision e Recall (~95%)

**Passo 3: Treinamento do Modelo 2 - Random Forest**
- **O que fazer**: Execute as c√©lulas que criam e treinam o modelo Random Forest
- **O que voc√™ ver√°**: 
  - Mensagem "Treinando Random Forest..."
  - Relat√≥rios de classifica√ß√£o similares ao modelo anterior
  - M√©tricas geralmente ligeiramente melhores
- **O que significa**: 
  - Random Forest √© um modelo mais complexo que combina m√∫ltiplas √°rvores de decis√£o
  - Geralmente apresenta melhor desempenho, mas √© menos interpret√°vel

**Passo 4: Compara√ß√£o dos Modelos**
- **O que fazer**: Execute as c√©lulas que comparam os dois modelos
- **O que voc√™ ver√°**: 
  - Uma tabela comparativa mostrando Accuracy, Precision, Recall e F1-Score lado a lado
  - Um gr√°fico de barras comparando as m√©tricas
  - Identifica√ß√£o do melhor modelo
- **O que significa**: 
  - Random Forest geralmente apresenta Accuracy ~97.4% vs ~96.5% da Regress√£o Log√≠stica
  - O melhor modelo √© selecionado para uso futuro

**Passo 5: Matriz de Confus√£o**
- **O que fazer**: Execute as c√©lulas que geram a matriz de confus√£o
- **O que voc√™ ver√°**: 
  - Uma matriz 2x2 mostrando:
    - **Verdadeiros Negativos (TN)**: Casos benignos corretamente identificados
    - **Falsos Positivos (FP)**: Casos benignos classificados como malignos (alarmes falsos)
    - **Falsos Negativos (FN)**: Casos malignos classificados como benignos (perigosos!)
    - **Verdadeiros Positivos (TP)**: Casos malignos corretamente identificados
- **O que significa**: 
  - **Falsos Negativos s√£o cr√≠ticos**: Um caso maligno n√£o detectado pode ser perigoso
  - O modelo ideal tem poucos ou nenhum falso negativo

**Passo 6: Feature Importance**
- **O que fazer**: Execute as c√©lulas que mostram a import√¢ncia das features
- **O que voc√™ ver√°**: 
  - Um gr√°fico de barras horizontal mostrando as features mais importantes
  - Top 10-15 features listadas com suas import√¢ncias
- **O que significa**: 
  - Features como `concave points_worst` e `perimeter_worst` s√£o as mais importantes
  - Isso indica que caracter√≠sticas de concavidade e tamanho s√£o mais preditivas

**Passo 7: An√°lise SHAP**
- **O que fazer**: Execute as c√©lulas que calculam e visualizam valores SHAP
- **O que voc√™ ver√°**: 
  - **Summary Plot**: Um gr√°fico mostrando como cada feature afeta as predi√ß√µes
  - **Bar Plot**: Import√¢ncia m√©dia das features segundo SHAP
  - **Waterfall Plot**: Explica√ß√£o de uma predi√ß√£o espec√≠fica
- **O que significa**: 
  - SHAP explica **por que** o modelo fez cada predi√ß√£o
  - Valores SHAP positivos (vermelho) aumentam a probabilidade de "Maligno"
  - Valores SHAP negativos (azul) diminuem a probabilidade de "Maligno"

**Passo 8: Discuss√£o Cr√≠tica**
- **O que fazer**: Leia as c√©lulas de discuss√£o sobre limita√ß√µes e considera√ß√µes √©ticas
- **O que voc√™ ver√°**: 
  - Lista de limita√ß√µes do modelo
  - Considera√ß√µes sobre uso pr√°tico
  - Considera√ß√µes √©ticas e m√©dicas
- **O que significa**: 
  - O modelo tem limita√ß√µes (dataset pequeno, n√£o considera contexto completo)
  - **Nunca deve substituir o diagn√≥stico m√©dico**
  - Deve ser usado apenas como ferramenta de apoio

#### üìä Sa√≠das Esperadas

1. **Relat√≥rios de classifica√ß√£o**: Tabelas com m√©tricas para cada modelo
2. **Gr√°fico comparativo**: Barras mostrando Accuracy, Precision, Recall, F1-Score
3. **Matriz de confus√£o**: Visualiza√ß√£o 2x2 dos acertos e erros
4. **Feature importance**: Gr√°fico de barras com top features
5. **SHAP Summary Plot**: Visualiza√ß√£o da import√¢ncia global das features
6. **SHAP Bar Plot**: Import√¢ncia m√©dia segundo SHAP
7. **SHAP Waterfall Plot**: Explica√ß√£o de uma predi√ß√£o espec√≠fica

#### üí° Interpreta√ß√£o dos Resultados

- **M√©tricas altas (>95%)**: Indicam que o modelo est√° funcionando bem, mas lembre-se: em medicina, at√© 1% de erro pode ser significativo
- **Recall de ~93%**: Significa que 7% dos casos malignos n√£o s√£o detectados. Isso √© cr√≠tico e precisa ser melhorado
- **Precision de 100% (Random Forest)**: Significa que quando o modelo diz "maligno", est√° sempre correto - n√£o h√° falsos alarmes
- **Feature importance**: Confirma que caracter√≠sticas de tamanho e forma s√£o mais importantes que textura
- **SHAP**: Fornece transpar√™ncia sobre as decis√µes do modelo, essencial para confian√ßa m√©dica

#### ‚û°Ô∏è Pr√≥ximos Passos

Ap√≥s completar este notebook, voc√™ pode:
- Explorar os notebooks de vis√£o computacional (03-06) para classifica√ß√£o de imagens
- Usar o modelo treinado para fazer predi√ß√µes em novos dados
- Ajustar hiperpar√¢metros para melhorar o desempenho

---

### Notebook 03: Explora√ß√£o de Imagens de Pneumonia

#### üéØ Objetivo

Este notebook realiza uma an√°lise explorat√≥ria do dataset de imagens de raio-X de t√≥rax para detec√ß√£o de pneumonia. Ele baixa o dataset, explora sua estrutura, visualiza amostras de imagens e analisa a distribui√ß√£o das classes.

#### üìã Pr√©-requisitos

- Python 3.8+ instalado
- Depend√™ncias instaladas (especialmente `kagglehub` para download)
- Conex√£o com internet (para baixar o dataset do Kaggle)

#### üìù Passo a Passo

**Passo 1: Download do Dataset**
- **O que fazer**: Execute a c√©lula que baixa o dataset do Kaggle
- **O que voc√™ ver√°**: 
  - Mensagens de progresso do download
  - Caminho onde o dataset foi salvo
  - Pode levar alguns minutos dependendo da conex√£o
- **O que significa**: 
  - O dataset ser√° baixado automaticamente usando `kagglehub`
  - As imagens ser√£o organizadas em pastas: `train/NORMAL/`, `train/PNEUMONIA/`, `test/`, `val/`

**Passo 2: An√°lise da Estrutura**
- **O que fazer**: Execute as c√©lulas que analisam a estrutura de diret√≥rios
- **O que voc√™ ver√°**: 
  - Contagem de imagens em cada pasta
  - Distribui√ß√£o entre classes (Normal vs Pneumonia)
  - Estrutura de diret√≥rios
- **O que significa**: 
  - Voc√™ ver√° milhares de imagens (ex: ~1300 Normal, ~3900 Pneumonia no treino)
  - H√° um desbalanceamento significativo (mais casos de pneumonia)
  - Os dados j√° v√™m divididos em treino/teste/valida√ß√£o

**Passo 3: Visualiza√ß√£o de Amostras**
- **O que fazer**: Execute as c√©lulas que mostram imagens de exemplo
- **O que voc√™ ver√°**: 
  - Grid de imagens mostrando exemplos de cada classe
  - Imagens de raio-X de t√≥rax em escala de cinza
  - Labels indicando "Normal" ou "Pneumonia"
- **O que significa**: 
  - **Normal**: Pulm√µes limpos, sem opacidades
  - **Pneumonia**: Opacidades brancas (infiltrados) indicando infec√ß√£o
  - As diferen√ßas podem ser sutis, o que torna o problema desafiador

**Passo 4: An√°lise de Dimens√µes**
- **O que fazer**: Execute as c√©lulas que verificam as dimens√µes das imagens
- **O que voc√™ ver√°**: 
  - Estat√≠sticas sobre largura, altura e formato das imagens
  - Algumas imagens podem ter tamanhos diferentes
- **O que significa**: 
  - As imagens precisar√£o ser redimensionadas para um tamanho uniforme antes do treinamento
  - Geralmente redimensionamos para 224x224 pixels

**Passo 5: An√°lise de Qualidade**
- **O que fazer**: Execute as c√©lulas que verificam a qualidade das imagens
- **O que voc√™ ver√°**: 
  - Verifica√ß√£o de imagens corrompidas ou inv√°lidas
  - Estat√≠sticas sobre canais de cor (RGB vs escala de cinza)
- **O que significa**: 
  - A maioria das imagens de raio-X s√£o em escala de cinza, mas algumas podem ter 3 canais
  - Imagens corrompidas ser√£o identificadas e podem ser removidas

**Passo 6: Distribui√ß√£o de Classes**
- **O que fazer**: Execute as c√©lulas que visualizam a distribui√ß√£o
- **O que voc√™ ver√°**: 
  - Gr√°ficos de barras mostrando contagem por classe
  - Gr√°ficos de pizza mostrando propor√ß√µes
- **O que significa**: 
  - H√° mais imagens de pneumonia que normais (desbalanceamento)
  - Isso ser√° tratado durante o treinamento com t√©cnicas como data augmentation e class weights

#### üìä Sa√≠das Esperadas

1. **Mensagens de download**: Progresso do download do dataset
2. **Estat√≠sticas de estrutura**: Contagem de imagens por pasta e classe
3. **Grid de imagens**: Visualiza√ß√£o de amostras de cada classe
4. **An√°lise de dimens√µes**: Estat√≠sticas sobre tamanhos das imagens
5. **Gr√°ficos de distribui√ß√£o**: Barras e pizza mostrando propor√ß√µes de classes

#### üí° Interpreta√ß√£o dos Resultados

- **Dataset grande**: Milhares de imagens fornecem dados suficientes para treinar uma CNN
- **Desbalanceamento**: Mais casos de pneumonia √© esperado em um dataset m√©dico real
- **Qualidade vari√°vel**: Imagens podem ter diferentes resolu√ß√µes e qualidades, o que √© normal
- **Diferen√ßas sutis**: As diferen√ßas entre Normal e Pneumonia podem ser dif√≠ceis de ver a olho nu, mas o modelo aprender√° padr√µes

#### ‚û°Ô∏è Pr√≥ximos Passos

Ap√≥s completar este notebook, voc√™ est√° pronto para o **Notebook 04: Modelagem CNN para Pneumonia**, onde uma rede neural convolucional ser√° treinada para classificar as imagens.

---

### Notebook 04: Modelagem CNN para Pneumonia

#### üéØ Objetivo

Este notebook treina uma **Rede Neural Convolucional (CNN)** para classificar imagens de raio-X de t√≥rax como Normal ou Pneumonia. Voc√™ ver√° o processo completo: pr√©-processamento, treinamento, avalia√ß√£o e interpretabilidade com Grad-CAM.

#### üìã Pr√©-requisitos

- Notebook 03 executado (dataset baixado e explorado)
- TensorFlow/Keras instalado
- GPU opcional (mas recomendado para treinamento mais r√°pido)

#### üìù Passo a Passo

**Passo 1: Carregamento e Divis√£o dos Dados**
- **O que fazer**: Execute as c√©lulas que carregam as imagens e dividem em treino/valida√ß√£o/teste
- **O que voc√™ ver√°**: 
  - Mensagens mostrando quantas imagens foram carregadas
  - Informa√ß√µes sobre a divis√£o: 60% treino, 20% valida√ß√£o, 20% teste
  - Estat√≠sticas de distribui√ß√£o de classes
- **O que significa**: 
  - As imagens s√£o carregadas e organizadas em batches para efici√™ncia
  - A divis√£o mant√©m a propor√ß√£o de classes (estratifica√ß√£o)

**Passo 2: Data Augmentation**
- **O que fazer**: Execute as c√©lulas que configuram data augmentation
- **O que voc√™ ver√°**: 
  - Configura√ß√µes de transforma√ß√µes: rota√ß√£o, zoom, deslocamento, etc.
- **O que significa**: 
  - **Data augmentation** cria varia√ß√µes das imagens (rotacionadas, ampliadas, etc.)
  - Isso aumenta a diversidade do dataset e reduz overfitting
  - Apenas aplicado no conjunto de treino

**Passo 3: Cria√ß√£o do Modelo CNN**
- **O que fazer**: Execute as c√©lulas que criam a arquitetura da CNN
- **O que voc√™ ver√°**: 
  - Resumo da arquitetura mostrando todas as camadas
  - N√∫mero total de par√¢metros (milh√µes)
  - Estrutura: camadas convolucionais ‚Üí pooling ‚Üí camadas densas
- **O que significa**: 
  - **Camadas convolucionais**: Detectam padr√µes (bordas, texturas, formas)
  - **Pooling**: Reduz dimens√£o, mantendo informa√ß√µes importantes
  - **Camadas densas**: Fazem a classifica√ß√£o final

**Passo 4: Compila√ß√£o do Modelo**
- **O que fazer**: Execute as c√©lulas que compilam o modelo
- **O que voc√™ ver√°**: 
  - Configura√ß√µes: otimizador (Adam), fun√ß√£o de loss, m√©tricas
- **O que significa**: 
  - **Adam**: Algoritmo de otimiza√ß√£o eficiente
  - **Categorical Crossentropy**: Fun√ß√£o de loss adequada para classifica√ß√£o
  - **M√©tricas**: Accuracy, Precision, Recall ser√£o monitoradas

**Passo 5: Treinamento**
- **O que fazer**: Execute a c√©lula que inicia o treinamento
- **O que voc√™ ver√°**: 
  - Progresso por √©poca mostrando:
    - Loss (erro) no treino e valida√ß√£o
    - Accuracy no treino e valida√ß√£o
    - Tempo por √©poca
  - Pode levar de 30 minutos a v√°rias horas dependendo do hardware
- **O que significa**: 
  - O modelo est√° aprendendo a distinguir Normal de Pneumonia
  - **Loss diminuindo**: O modelo est√° melhorando
  - **Accuracy aumentando**: O modelo est√° acertando mais
  - **Early stopping**: O treinamento para automaticamente se n√£o melhorar

**Passo 6: Visualiza√ß√£o do Hist√≥rico de Treinamento**
- **O que fazer**: Execute as c√©lulas que plotam gr√°ficos do hist√≥rico
- **O que voc√™ ver√°**: 
  - Gr√°ficos de Loss (treino vs valida√ß√£o) ao longo das √©pocas
  - Gr√°ficos de Accuracy (treino vs valida√ß√£o) ao longo das √©pocas
- **O que significa**: 
  - **Curvas convergindo**: O modelo est√° aprendendo bem
  - **Gap grande entre treino e valida√ß√£o**: Poss√≠vel overfitting
  - **Valida√ß√£o melhorando**: O modelo est√° generalizando bem

**Passo 7: Avalia√ß√£o no Conjunto de Teste**
- **O que fazer**: Execute as c√©lulas que avaliam o modelo no conjunto de teste
- **O que voc√™ ver√°**: 
  - M√©tricas finais: Accuracy, Precision, Recall, F1-Score
  - Matriz de confus√£o
  - Curva ROC e AUC
- **O que significa**: 
  - **Accuracy > 80%**: Bom desempenho para uma CNN simples
  - **Matriz de confus√£o**: Mostra quantos casos foram classificados corretamente
  - **ROC-AUC**: Mede a capacidade de distinguir entre classes (quanto maior, melhor)

**Passo 8: Visualiza√ß√£o de Predi√ß√µes**
- **O que fazer**: Execute as c√©lulas que mostram predi√ß√µes em imagens de teste
- **O que voc√™ ver√°**: 
  - Grid de imagens com predi√ß√µes
  - Labels mostrando: Classe verdadeira vs Predi√ß√£o vs Confian√ßa
  - Imagens corretas e incorretas destacadas
- **O que significa**: 
  - **Confian√ßa alta (>90%)**: O modelo est√° muito certo
  - **Confian√ßa baixa (<70%)**: O modelo est√° incerto
  - **Erros**: Casos dif√≠ceis que o modelo confundiu

**Passo 9: Grad-CAM (Interpretabilidade)**
- **O que fazer**: Execute as c√©lulas que geram visualiza√ß√µes Grad-CAM
- **O que voc√™ ver√°**: 
  - Imagens originais lado a lado com heatmaps coloridos
  - Regi√µes em vermelho/laranja: √°reas que o modelo considera importantes
  - Superposi√ß√£o do heatmap na imagem original
- **O que significa**: 
  - **Grad-CAM** mostra **onde** o modelo est√° olhando
  - Regi√µes destacadas devem corresponder a √°reas clinicamente relevantes (pulm√µes)
  - Se o modelo foca em √°reas irrelevantes, pode indicar problemas

#### üìä Sa√≠das Esperadas

1. **Resumo da arquitetura**: Estrutura completa da CNN
2. **Progresso de treinamento**: M√©tricas por √©poca
3. **Gr√°ficos de hist√≥rico**: Loss e Accuracy ao longo do tempo
4. **M√©tricas finais**: Tabela com Accuracy, Precision, Recall, F1-Score
5. **Matriz de confus√£o**: Visualiza√ß√£o 2x2 dos acertos e erros
6. **Curva ROC**: Gr√°fico mostrando performance de classifica√ß√£o
7. **Grid de predi√ß√µes**: Imagens com predi√ß√µes e confian√ßas
8. **Grad-CAM heatmaps**: Visualiza√ß√µes mostrando regi√µes importantes

#### üí° Interpreta√ß√£o dos Resultados

- **Accuracy > 80%**: Bom desempenho, mas em medicina sempre buscamos melhorar
- **Recall alto**: Importante para n√£o perder casos de pneumonia
- **Grad-CAM focado nos pulm√µes**: Indica que o modelo est√° aprendendo padr√µes corretos
- **Overfitting**: Se accuracy de treino >> accuracy de valida√ß√£o, o modelo est√° decorando os dados
- **Tempo de treinamento**: CNNs s√£o computacionalmente intensivas, mas os resultados valem a pena

#### ‚û°Ô∏è Pr√≥ximos Passos

Ap√≥s completar este notebook, voc√™ pode:
- Explorar os notebooks de c√¢ncer de mama (05-06)
- Experimentar diferentes arquiteturas de CNN
- Ajustar hiperpar√¢metros para melhorar o desempenho

---

### Notebook 05: Explora√ß√£o de Mamografias

#### üéØ Objetivo

Este notebook realiza uma an√°lise explorat√≥ria do dataset de mamografias (CBIS-DDSM) para detec√ß√£o de c√¢ncer de mama. Similar ao notebook 03, mas focado em imagens de mamografia.

#### üìã Pr√©-requisitos

- Python 3.8+ instalado
- Depend√™ncias instaladas (especialmente `kagglehub`)
- Conex√£o com internet
- **Nota**: Este dataset √© maior e pode levar mais tempo para baixar

#### üìù Passo a Passo

**Passo 1: Download do Dataset**
- **O que fazer**: Execute a c√©lula que baixa o dataset CBIS-DDSM
- **O que voc√™ ver√°**: 
  - Mensagens de progresso (pode levar 10-30 minutos)
  - Caminho onde o dataset foi salvo
  - Estrutura de diret√≥rios complexa (o dataset CBIS-DDSM tem estrutura aninhada)
- **O que significa**: 
  - Este dataset √© maior e mais complexo que o de pneumonia
  - As imagens s√£o de alta resolu√ß√£o (mamografias detalhadas)
  - Estrutura: `train/BENIGN/`, `train/MALIGNANT/`, etc.

**Passo 2: An√°lise da Estrutura**
- **O que fazer**: Execute as c√©lulas que analisam a estrutura
- **O que voc√™ ver√°**: 
  - Contagem de imagens por classe
  - Estrutura de diret√≥rios (pode ser aninhada)
  - Estat√≠sticas de distribui√ß√£o
- **O que significa**: 
  - Dataset pode ter centenas ou milhares de imagens
  - Distribui√ß√£o entre Benigno e Maligno
  - Estrutura pode requerer navega√ß√£o em subdiret√≥rios

**Passo 3: Visualiza√ß√£o de Amostras**
- **O que fazer**: Execute as c√©lulas que mostram imagens de exemplo
- **O que voc√™ ver√°**: 
  - Grid de mamografias em escala de cinza
  - Imagens de alta resolu√ß√£o mostrando tecido mam√°rio
  - Labels indicando "Benigno" ou "Maligno"
- **O que significa**: 
  - **Mamografias**: Imagens de raio-X das mamas
  - **Les√µes benignas**: Massas n√£o cancerosas
  - **Les√µes malignas**: C√¢ncer de mama
  - Diferen√ßas podem ser muito sutis e requerem an√°lise especializada

**Passo 4: An√°lise de Dimens√µes e Qualidade**
- **O que fazer**: Execute as c√©lulas que verificam dimens√µes e qualidade
- **O que voc√™ ver√°**: 
  - Estat√≠sticas sobre tamanhos das imagens (geralmente grandes, ex: 2000x3000 pixels)
  - Verifica√ß√£o de imagens corrompidas
  - Informa√ß√µes sobre formato (geralmente DICOM ou PNG)
- **O que significa**: 
  - Imagens de alta resolu√ß√£o precisar√£o ser redimensionadas para treinamento (ex: 256x256)
  - Formato DICOM √© comum em imagens m√©dicas e pode requerer convers√£o

**Passo 5: Distribui√ß√£o de Classes**
- **O que fazer**: Execute as c√©lulas que visualizam a distribui√ß√£o
- **O que voc√™ ver√°**: 
  - Gr√°ficos mostrando propor√ß√£o de Benigno vs Maligno
  - Estat√≠sticas de contagem
- **O que significa**: 
  - Pode haver desbalanceamento (mais casos benignos √© comum)
  - Isso ser√° tratado durante o treinamento

#### üìä Sa√≠das Esperadas

1. **Mensagens de download**: Progresso (pode ser longo)
2. **Estat√≠sticas de estrutura**: Contagem e organiza√ß√£o de imagens
3. **Grid de mamografias**: Visualiza√ß√£o de amostras
4. **An√°lise de dimens√µes**: Tamanhos das imagens (geralmente grandes)
5. **Gr√°ficos de distribui√ß√£o**: Propor√ß√µes de classes

#### üí° Interpreta√ß√£o dos Resultados

- **Dataset complexo**: Estrutura aninhada √© comum em datasets m√©dicos profissionais
- **Alta resolu√ß√£o**: Imagens detalhadas s√£o importantes para detectar les√µes pequenas
- **Diferen√ßas sutis**: Distinguir benigno de maligno √© desafiador mesmo para especialistas
- **Desbalanceamento**: Mais casos benignos √© esperado em dados reais

#### ‚û°Ô∏è Pr√≥ximos Passos

Ap√≥s completar este notebook, voc√™ est√° pronto para o **Notebook 06: Modelagem CNN para C√¢ncer de Mama**, onde uma CNN ser√° treinada para classificar as mamografias.

---

### Notebook 06: Modelagem CNN para C√¢ncer de Mama

#### üéØ Objetivo

Este notebook treina uma **CNN** para classificar mamografias como Benignas ou Malignas. Similar ao notebook 04, mas adaptado para imagens em escala de cinza e com arquitetura otimizada para o problema espec√≠fico.

#### üìã Pr√©-requisitos

- Notebook 05 executado (dataset baixado)
- TensorFlow/Keras instalado
- GPU recomendado (treinamento pode ser longo)

#### üìù Passo a Passo

**Passo 1: Carregamento e Pr√©-processamento**
- **O que fazer**: Execute as c√©lulas que carregam e preprocessam as imagens
- **O que voc√™ ver√°**: 
  - Mensagens sobre carregamento de imagens
  - Convers√£o para escala de cinza (1 canal em vez de 3)
  - Redimensionamento para 256x256 pixels
  - Divis√£o em treino/valida√ß√£o/teste
- **O que significa**: 
  - Mamografias s√£o naturalmente em escala de cinza
  - Redimensionamento √© necess√°rio para efici√™ncia computacional
  - Tamanho 256x256 √© um bom equil√≠brio entre detalhe e velocidade

**Passo 2: Data Augmentation**
- **O que fazer**: Execute as c√©lulas que configuram augmentation
- **O que voc√™ ver√°**: 
  - Configura√ß√µes similares ao notebook 04, mas adaptadas para escala de cinza
  - Rota√ß√£o, zoom, deslocamento, brightness adjustment
- **O que significa**: 
  - Augmentation √© especialmente importante para datasets menores
  - Varia√ß√µes de brilho simulam diferentes condi√ß√µes de imagem

**Passo 3: Cria√ß√£o do Modelo CNN**
- **O que fazer**: Execute as c√©lulas que criam a arquitetura
- **O que voc√™ ver√°**: 
  - Arquitetura com 5 blocos convolucionais (mais profunda que pneumonia)
  - Global Average Pooling (t√©cnica avan√ßada para reduzir overfitting)
  - Batch Normalization e Dropout para regulariza√ß√£o
- **O que significa**: 
  - Arquitetura mais profunda captura padr√µes mais complexos
  - T√©cnicas de regulariza√ß√£o previnem overfitting
  - Global Average Pooling reduz par√¢metros e melhora generaliza√ß√£o

**Passo 4: Compila√ß√£o com Focal Loss (Opcional)**
- **O que fazer**: Execute as c√©lulas que compilam o modelo
- **O que voc√™ ver√°**: 
  - Op√ß√£o de usar Focal Loss ou Categorical Crossentropy
  - Focal Loss √© especialmente √∫til para classes desbalanceadas
- **O que significa**: 
  - **Focal Loss**: Foca em exemplos dif√≠ceis, √∫til quando h√° desbalanceamento
  - **Class Weights**: Ajusta a import√¢ncia de cada classe durante treinamento

**Passo 5: Treinamento**
- **O que fazer**: Execute a c√©lula que inicia o treinamento
- **O que voc√™ ver√°**: 
  - Progresso similar ao notebook 04
  - Pode levar mais tempo devido √† arquitetura mais profunda
  - Early stopping e redu√ß√£o de learning rate autom√°ticos
- **O que significa**: 
  - O modelo est√° aprendendo padr√µes sutis em mamografias
  - Callbacks autom√°ticos otimizam o treinamento

**Passo 6: Avalia√ß√£o e M√©tricas**
- **O que fazer**: Execute as c√©lulas de avalia√ß√£o
- **O que voc√™ ver√°**: 
  - M√©tricas completas: Accuracy, Precision, Recall, F1-Score
  - Matriz de confus√£o
  - Curva ROC
  - An√°lise por classe
- **O que significa**: 
  - **Recall alto para Maligno**: Cr√≠tico para n√£o perder casos de c√¢ncer
  - **Precision alta**: Evita alarmes falsos e bi√≥psias desnecess√°rias
  - M√©tricas balanceadas indicam bom desempenho geral

**Passo 7: Grad-CAM**
- **O que fazer**: Execute as c√©lulas que geram Grad-CAM
- **O que voc√™ ver√°**: 
  - Heatmaps mostrando regi√µes importantes nas mamografias
  - Superposi√ß√£o nas imagens originais
  - An√°lise de casos corretos e incorretos
- **O que significa**: 
  - Regi√µes destacadas devem corresponder a les√µes suspeitas
  - Se o modelo foca em √°reas irrelevantes, pode indicar problemas
  - Grad-CAM √© essencial para valida√ß√£o cl√≠nica

**Passo 8: Valida√ß√£o e Discuss√£o**
- **O que fazer**: Leia as c√©lulas de discuss√£o sobre resultados
- **O que voc√™ ver√°**: 
  - An√°lise cr√≠tica do desempenho
  - Limita√ß√µes do modelo
  - Considera√ß√µes para uso cl√≠nico
- **O que significa**: 
  - Mesmo com alta accuracy, o modelo tem limita√ß√µes
  - **Nunca deve substituir diagn√≥stico m√©dico**
  - Pode ser usado como ferramenta de triagem/apoio

#### üìä Sa√≠das Esperadas

1. **Resumo da arquitetura**: CNN com 5 blocos convolucionais
2. **Progresso de treinamento**: M√©tricas por √©poca
3. **Gr√°ficos de hist√≥rico**: Loss e Accuracy
4. **M√©tricas finais**: Tabela completa de avalia√ß√£o
5. **Matriz de confus√£o**: Performance detalhada
6. **Curva ROC**: Capacidade de classifica√ß√£o
7. **Grad-CAM heatmaps**: Regi√µes importantes nas mamografias

#### üí° Interpreta√ß√£o dos Resultados

- **Accuracy > 80%**: Bom, mas em c√¢ncer sempre buscamos melhorar
- **Recall para Maligno > 90%**: Essencial - n√£o podemos perder casos de c√¢ncer
- **Grad-CAM focado em les√µes**: Valida que o modelo est√° aprendendo padr√µes corretos
- **Focal Loss**: Pode melhorar performance em classes desbalanceadas
- **Arquitetura profunda**: Captura padr√µes complexos, mas requer mais dados

#### ‚û°Ô∏è Pr√≥ximos Passos

Ap√≥s completar todos os notebooks, voc√™ pode:
- Comparar resultados entre diferentes abordagens
- Experimentar transfer learning (usar modelos pr√©-treinados)
- Ajustar hiperpar√¢metros para otimiza√ß√£o
- Integrar os modelos em uma aplica√ß√£o

---

## üî¨ Detalhes T√©cnicos

Esta se√ß√£o apresenta os detalhes t√©cnicos do projeto, incluindo estrat√©gias de pr√©-processamento, justificativas dos modelos e discuss√µes sobre m√©tricas.

### Estrat√©gias de Pr√©-processamento

#### Dados Tabulares

**1. Limpeza de Dados**

- **Remo√ß√£o de colunas n√£o relevantes**:
  - `id`: Identificador √∫nico (n√£o preditivo)
  - `Unnamed: 32`: Coluna vazia/duplicada

- **Tratamento de valores ausentes e infinitos**:
  - Substitui√ß√£o de valores infinitos por NaN
  - Preenchimento de NaN com a m√©dia da coluna (se necess√°rio)
  - No dataset utilizado, n√£o foram encontrados valores ausentes

- **Sele√ß√£o de features**:
  - Utiliza√ß√£o apenas de colunas num√©ricas
  - Remo√ß√£o de colunas identificadoras

**2. Normaliza√ß√£o**

- **StandardScaler**: Normaliza√ß√£o das features para m√©dia zero e desvio padr√£o unit√°rio
- **Justificativa**:
  - Diferentes features t√™m escalas distintas (ex: √°rea vs. textura)
  - Modelos lineares (Regress√£o Log√≠stica) s√£o sens√≠veis √† escala
  - Facilita converg√™ncia e melhora desempenho

**3. Divis√£o dos Dados**

- **Estrat√©gia**: Divis√£o estratificada em tr√™s conjuntos
  - **Treino (60%)**: 341 amostras - Para treinar os modelos
  - **Valida√ß√£o (20%)**: 114 amostras - Para ajuste de hiperpar√¢metros e sele√ß√£o de modelo
  - **Teste (20%)**: 114 amostras - Para avalia√ß√£o final e relat√≥rio de desempenho
- **Estratifica√ß√£o**: Mant√©m a propor√ß√£o de classes em cada conjunto
- **Random State**: 42 (para reprodutibilidade)

#### Dados de Imagens

**1. Redimensionamento e Normaliza√ß√£o**

- **Redimensionamento**: Todas as imagens foram redimensionadas para tamanhos fixos
  - Pneumonia: 224x224 pixels (RGB)
  - C√¢ncer de Mama: 256x256 pixels (escala de cinza)
- **Normaliza√ß√£o**: Pixels normalizados para o intervalo [0, 1] dividindo por 255
- **Convers√£o de Cores**:
  - Pneumonia: Mantido RGB (3 canais)
  - C√¢ncer de Mama: Convertido para escala de cinza (1 canal)

**2. Data Augmentation**

Para aumentar a robustez do modelo e reduzir overfitting, foram aplicadas t√©cnicas de data augmentation no conjunto de treino:

- **Rota√ß√£o**: ¬±30 graus
- **Deslocamento**: Horizontal e vertical (¬±15%)
- **Zoom**: ¬±20%
- **Flip Horizontal**: Espelhamento aleat√≥rio
- **Flip Vertical**: Espelhamento vertical (para c√¢ncer de mama)
- **Brightness**: Ajuste de brilho [0.8, 1.2]
- **Shear**: Cisalhamento de ¬±10%

**Justificativa**:
- Aumenta a diversidade do conjunto de treino
- Melhora generaliza√ß√£o
- Simula varia√ß√µes naturais em imagens m√©dicas (posicionamento, √¢ngulo, etc.)

**3. Divis√£o dos Dados**

- **Treino (60%)**: Para treinar o modelo
- **Valida√ß√£o (20%)**: Para ajuste de hiperpar√¢metros e early stopping
- **Teste (20%)**: Para avalia√ß√£o final
- **Estratifica√ß√£o**: Mant√©m propor√ß√£o de classes em cada conjunto

### Modelos Utilizados e Justificativa

#### Dados Tabulares

**1. Regress√£o Log√≠stica**

**Justificativa**:
- Modelo linear interpret√°vel e eficiente
- Funciona bem como baseline para compara√ß√£o
- R√°pido para treinar e fazer predi√ß√µes
- Boa performance em problemas de classifica√ß√£o bin√°ria
- Probabilidades de sa√≠da s√£o calibradas

**Par√¢metros**:
- `solver='lbfgs'`: Algoritmo robusto para problemas pequenos/m√©dios
- `C=1.0`: Regulariza√ß√£o L2 (inverso da for√ßa de regulariza√ß√£o)
- `max_iter=1000`: N√∫mero m√°ximo de itera√ß√µes
- `random_state=42`: Reprodutibilidade

**Vantagens**:
- Interpretabilidade (coeficientes lineares)
- Baixa complexidade computacional
- Menor risco de overfitting

**Desvantagens**:
- Assume rela√ß√£o linear entre features e target
- Pode n√£o capturar intera√ß√µes complexas

**2. Random Forest**

**Justificativa**:
- Algoritmo de ensemble robusto e poderoso
- Capaz de capturar rela√ß√µes n√£o-lineares
- Menos propenso a overfitting que √°rvores individuais
- Fornece feature importance nativa
- Geralmente apresenta melhor desempenho que modelos lineares

**Par√¢metros**:
- `n_estimators=100`: N√∫mero de √°rvores no ensemble
- `max_depth=10`: Profundidade m√°xima das √°rvores (controla complexidade)
- `random_state=42`: Reprodutibilidade

**Vantagens**:
- Alta capacidade de modelagem
- Robustez a outliers
- Feature importance integrada
- Boa performance geral

**Desvantagens**:
- Menos interpret√°vel que modelos lineares
- Maior complexidade computacional
- Pode ser mais dif√≠cil de explicar para n√£o-especialistas

**3. Pipeline de Processamento**

Ambos os modelos foram implementados em um pipeline que inclui:

1. **StandardScaler**: Normaliza√ß√£o das features
2. **Modelo**: Regress√£o Log√≠stica ou Random Forest

Isso garante que:
- Novos dados sejam pr√©-processados da mesma forma
- O modelo salvo inclui todas as transforma√ß√µes necess√°rias

#### Dados de Imagens (CNNs)

**1. CNN para Pneumonia**

**Arquitetura**:
- **Input**: Imagens RGB 224x224x3
- **4 Blocos Convolucionais**:
  - Bloco 1: 32 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
  - Bloco 2: 64 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
  - Bloco 3: 128 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
  - Bloco 4: 128 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
- **Camadas Densas**:
  - Flatten
  - Dense(512) + BatchNorm + Dropout(0.5)
  - Dense(256) + BatchNorm + Dropout(0.5)
  - Dense(2, activation='softmax')

**Total de par√¢metros**: ~2-3 milh√µes

**2. CNN para C√¢ncer de Mama**

**Arquitetura**:
- **Input**: Imagens em escala de cinza 256x256x1
- **5 Blocos Convolucionais**:
  - Bloco 1: 32 filtros 5x5 + BatchNorm + MaxPooling 2x2 + Dropout 0.1
  - Bloco 2: 64 filtros 5x5 + BatchNorm + MaxPooling 2x2 + Dropout 0.15
  - Bloco 3: 128 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.2
  - Bloco 4: 256 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
  - Bloco 5: 256 filtros 3x3 + BatchNorm + MaxPooling 2x2 + Dropout 0.25
- **Global Average Pooling**: Reduz dimens√µes e previne overfitting
- **Camadas Densas**: Similar √† CNN de pneumonia, com L2 regularization

**Justificativa da arquitetura mais profunda**:
- Mamografias podem requerer an√°lise mais detalhada
- Mais camadas para capturar padr√µes sutis de les√µes
- Global Average Pooling reduz par√¢metros e melhora generaliza√ß√£o

**3. Configura√ß√µes de Treinamento**

- **Otimizador**: AdamW (com weight decay) ou Adam
- **Learning Rate**: 0.0001 (reduzido para treinamento mais est√°vel)
- **Loss**: Categorical Crossentropy ou Focal Loss (para classes desbalanceadas)
- **M√©tricas**: Accuracy, Precision, Recall
- **Batch Size**: 32
- **√âpocas**: 50 (com early stopping)
- **Early Stopping**: Patience=10, monitor='val_loss'
- **Model Checkpoint**: Salva melhor modelo baseado em val_loss e val_accuracy
- **ReduceLROnPlateau**: Reduz learning rate quando valida√ß√£o estagna

**4. Callbacks**

1. **ModelCheckpoint**: Salva o melhor modelo durante treinamento
2. **EarlyStopping**: Para treinamento quando n√£o h√° melhoria
3. **ReduceLROnPlateau**: Ajusta learning rate dinamicamente

### Justificativa da Escolha das M√©tricas

Em problemas de diagn√≥stico m√©dico, a escolha das m√©tricas de avalia√ß√£o √© cr√≠tica e deve considerar o contexto cl√≠nico e os custos associados a diferentes tipos de erro. Neste projeto, utilizamos quatro m√©tricas principais: **Accuracy**, **Precision**, **Recall** e **F1-Score**. A seguir, justificamos a escolha de cada uma:

#### Por que Accuracy n√£o √© suficiente?

A **Accuracy** (Acur√°cia) mede a propor√ß√£o de predi√ß√µes corretas sobre o total. Embora seja uma m√©trica intuitiva, ela pode ser enganosa em problemas m√©dicos, especialmente quando h√° desbalanceamento de classes:

- **Limita√ß√£o**: Em um dataset com 62% de casos benignos e 38% malignos, um modelo que sempre prediz "benigno" teria 62% de accuracy, mas seria completamente in√∫til para detectar c√¢ncer
- **Uso adequado**: A accuracy √© √∫til como m√©trica geral, mas n√£o deve ser a √∫nica considerada em diagn√≥stico m√©dico

#### Por que Recall √© cr√≠tico em diagn√≥stico m√©dico?

O **Recall** (Sensibilidade) mede a propor√ß√£o de casos positivos (malignos) que foram corretamente identificados:

- **Import√¢ncia cl√≠nica**: Em diagn√≥stico de c√¢ncer, **falsos negativos s√£o extremamente perigosos** - um caso maligno n√£o detectado pode resultar em progress√£o da doen√ßa e pior progn√≥stico
- **Interpreta√ß√£o**: Um Recall de 92.86% significa que o modelo detecta 92.86% dos casos malignos, mas ainda falha em detectar 7.14% (3 casos no nosso conjunto de teste)
- **Custo do erro**: O custo de n√£o detectar um c√¢ncer maligno √© muito maior que o custo de um falso positivo (que pode ser resolvido com exames adicionais)

#### Por que Precision √© importante?

A **Precision** (Precis√£o) mede a propor√ß√£o de predi√ß√µes positivas que s√£o realmente corretas:

- **Import√¢ncia cl√≠nica**: **Falsos positivos** podem causar ansiedade desnecess√°ria, exames invasivos adicionais (bi√≥psias) e custos m√©dicos
- **Interpreta√ß√£o**: Uma Precision de 100% (Random Forest) significa que quando o modelo prediz "maligno", est√° sempre correto - n√£o h√° falsos alarmes
- **Balanceamento**: Alta precision reduz o n√∫mero de bi√≥psias desnecess√°rias, mas n√£o deve comprometer o recall

#### Por que F1-Score √© uma m√©trica balanceada?

O **F1-Score** √© a m√©dia harm√¥nica entre Precision e Recall:

- **Vantagem**: Balanceia a import√¢ncia de detectar casos positivos (Recall) e evitar falsos alarmes (Precision)
- **Uso**: √ötil quando precisamos de uma √∫nica m√©trica que considere ambos os aspectos
- **Limita√ß√£o**: Assume que Precision e Recall t√™m igual import√¢ncia, o que pode n√£o ser verdade em todos os contextos m√©dicos

#### Considera√ß√µes para o Problema de C√¢ncer de Mama

Para diagn√≥stico de c√¢ncer de mama, a hierarquia de import√¢ncia das m√©tricas √©:

1. **Recall (mais cr√≠tico)**: N√£o perder casos malignos √© a prioridade m√°xima
2. **Precision (importante)**: Evitar alarmes falsos reduz ansiedade e custos
3. **F1-Score**: Fornece uma vis√£o balanceada do desempenho geral
4. **Accuracy**: √ötil como m√©trica geral, mas n√£o suficiente isoladamente

**Conclus√£o**: A combina√ß√£o dessas m√©tricas permite uma avalia√ß√£o completa do modelo, considerando tanto a capacidade de detectar casos cr√≠ticos quanto a precis√£o das predi√ß√µes positivas. Em um contexto cl√≠nico real, m√©dicos podem ajustar o threshold de decis√£o baseado na import√¢ncia relativa de Recall vs Precision para cada paciente espec√≠fico.

### Resultados e Interpreta√ß√£o

#### Dados Tabulares

**Desempenho dos Modelos**

**Regress√£o Log√≠stica**:
- **Accuracy (Teste)**: 96.49%
- **Precision (M)**: 97.67%
- **Recall (M)**: 92.86%
- **F1-Score (M)**: 95.24%

**Random Forest**:
- **Accuracy (Teste)**: 97.37%
- **Precision (M)**: 100.00%
- **Recall (M)**: 92.86%
- **F1-Score (M)**: 96.30%

**An√°lise Comparativa**:
O **Random Forest** apresentou desempenho ligeiramente superior em todas as m√©tricas:
- **Accuracy**: 0.88 pontos percentuais a mais
- **Precision**: 2.33 pontos percentuais a mais (100% vs 97.67%)
- **F1-Score**: 1.06 pontos percentuais a mais

Ambos os modelos apresentam desempenho excelente (>95% accuracy), indicando que o problema √© relativamente bem separ√°vel com as features dispon√≠veis.

**Matriz de Confus√£o (Random Forest)**:
```
                Predito
              B      M
Real    B    72     0
        M     3    39
```

- **Verdadeiros Negativos (TN)**: 72
- **Falsos Positivos (FP)**: 0
- **Falsos Negativos (FN)**: 3
- **Verdadeiros Positivos (TP)**: 39

**An√°lise**:
- Nenhum falso positivo: Todos os casos benignos foram corretamente identificados
- 3 falsos negativos: 3 casos malignos foram classificados como benignos
- **Impacto cl√≠nico**: Falsos negativos s√£o mais cr√≠ticos (caso maligno n√£o detectado)

**Feature Importance**:
As features mais importantes identificadas pelo Random Forest foram:

1. `concave points_worst` - Pontos c√¥ncavos (pior valor)
2. `perimeter_worst` - Per√≠metro (pior valor)
3. `concave points_mean` - Pontos c√¥ncavos (m√©dia)
4. `radius_worst` - Raio (pior valor)
5. `area_worst` - √Årea (pior valor)

**Interpreta√ß√£o**: Caracter√≠sticas relacionadas a concavidade e tamanho (per√≠metro, raio, √°rea) s√£o as mais preditivas, especialmente os valores "worst" (piores), que representam as caracter√≠sticas mais extremas encontradas.

**An√°lise SHAP**:
A an√°lise SHAP (SHapley Additive exPlanations) fornece interpretabilidade adicional:

**Insights Globais**:
- Confirma a import√¢ncia das features identificadas pela feature importance
- Mostra que valores altos de caracter√≠sticas como `concave points_worst` e `perimeter_worst` aumentam a probabilidade de diagn√≥stico maligno
- Valores baixos dessas caracter√≠sticas indicam diagn√≥stico benigno

**Interpreta√ß√£o Local**:
- Permite entender por que cada predi√ß√£o espec√≠fica foi feita
- √ötil para explicar decis√µes do modelo a m√©dicos e pacientes
- Mostra a contribui√ß√£o individual de cada feature para cada caso

#### Dados de Imagens

**M√©tricas de Avalia√ß√£o**:
Ambos os modelos de CNN foram avaliados usando:
- **Accuracy**: Taxa de acerto geral
- **Precision**: Precis√£o por classe
- **Recall**: Sensibilidade por classe
- **F1-Score**: M√©dia harm√¥nica de precision e recall
- **ROC-AUC**: √Årea sob a curva ROC
- **Matriz de Confus√£o**: Visualiza√ß√£o de erros

**Interpretabilidade: Grad-CAM**:
**Grad-CAM (Gradient-weighted Class Activation Mapping)** foi implementado para visualizar as regi√µes da imagem que mais influenciam a predi√ß√£o do modelo.

**Como funciona**:
1. Calcula gradientes da classe predita em rela√ß√£o √† √∫ltima camada convolucional
2. Cria um heatmap mostrando regi√µes importantes
3. Superp√µe o heatmap na imagem original

**Benef√≠cios**:
- **Transpar√™ncia**: Mostra o que o modelo est√° "vendo"
- **Valida√ß√£o**: Permite verificar se o modelo foca em regi√µes clinicamente relevantes
- **Debugging**: Identifica se o modelo est√° aprendendo padr√µes corretos ou artefatos
- **Confian√ßa**: Ajuda m√©dicos a confiar nas predi√ß√µes do modelo

**Aplica√ß√£o**:
- Visualiza√ß√£o de regi√µes de aten√ß√£o para casos de pneumonia
- Identifica√ß√£o de les√µes suspeitas em mamografias
- An√°lise de casos corretos e incorretos

### Discuss√£o Cr√≠tica e Limita√ß√µes

#### Limita√ß√µes Identificadas

**1. Dataset Limitado**:
- Apenas ~570 amostras podem limitar generaliza√ß√£o
- Dataset espec√≠fico de c√¢ncer de mama
- Poss√≠vel vi√©s geogr√°fico/temporal

**2. Features Dispon√≠veis**:
- Apenas caracter√≠sticas num√©ricas de exames
- N√£o considera hist√≥rico m√©dico, gen√©tica ou estilo de vida
- Pode n√£o capturar todas as intera√ß√µes relevantes

**3. Desbalanceamento de Classes**:
- Classe benigna tem mais amostras que maligna
- Apesar da estratifica√ß√£o, pode impactar casos raros

**4. Generaliza√ß√£o**:
- Modelo treinado em dados hist√≥ricos
- N√£o testado em diferentes popula√ß√µes
- Valida√ß√£o externa necess√°ria

**5. Interpretabilidade**:
- Random Forest √© mais complexo que modelos lineares
- SHAP ajuda, mas requer conhecimento t√©cnico

#### Viabilidade de Uso Pr√°tico

**Pontos Positivos**:
- Alta acur√°cia (>97%) sugere potencial para triagem inicial
- Modelo r√°pido e eficiente
- Pode auxiliar na prioriza√ß√£o de casos
- Interpretabilidade via SHAP e Grad-CAM

**Considera√ß√µes Importantes**:
- **N√ÉO substitui o diagn√≥stico m√©dico** - deve ser usado apenas como ferramenta de apoio
- Requer valida√ß√£o cl√≠nica extensiva
- Necessita integra√ß√£o com sistemas hospitalares
- Treinamento de equipe m√©dica necess√°rio
- Monitoramento cont√≠nuo essencial

**Casos de Uso Sugeridos**:
- Triagem inicial para prioriza√ß√£o
- Segunda opini√£o para valida√ß√£o
- Educa√ß√£o m√©dica
- Pesquisa e identifica√ß√£o de padr√µes
- Controle de qualidade

**Limita√ß√µes para Uso Cl√≠nico**:
- N√£o deve ser √∫nico crit√©rio para diagn√≥stico
- N√£o considera contexto cl√≠nico completo
- Pode gerar falsos positivos/negativos graves
- Requer aprova√ß√£o regulat√≥ria
- Necessita auditoria e responsabiliza√ß√£o

### Considera√ß√µes √âticas e M√©dicas

**Privacidade e Seguran√ßa**:
- Dados m√©dicos sens√≠veis requerem prote√ß√£o rigorosa (LGPD, HIPAA)
- Anonimiza√ß√£o adequada necess√°ria
- Criptografia e controle de acesso essenciais

**Responsabilidade e Transpar√™ncia**:
- Responsabilidade final sempre do m√©dico
- Transpar√™ncia sobre limita√ß√µes e taxa de erro
- Documenta√ß√£o clara do processo
- Possibilidade de apela√ß√£o/revis√£o

**Vi√©s e Equidade**:
- Verificar vi√©s contra grupos demogr√°ficos
- Garantir representatividade do dataset
- Monitorar desempenho em subpopula√ß√µes
- Evitar discrimina√ß√£o

**Impacto no Relacionamento M√©dico-Paciente**:
- IA n√£o deve substituir comunica√ß√£o m√©dico-paciente
- Explica√ß√µes compreens√≠veis para pacientes
- Respeitar autonomia do paciente
- Manter humaniza√ß√£o do cuidado

**Qualidade e Valida√ß√£o**:
- Valida√ß√£o em m√∫ltiplos centros
- Compara√ß√£o com padr√£o-ouro
- Estudos prospectivos necess√°rios
- Revis√£o peri√≥dica do modelo

**Princ√≠pio Fundamental**: O modelo deve sempre servir como **FERRAMENTA DE APOIO** √† decis√£o m√©dica, nunca como substituto do julgamento cl√≠nico profissional.

---

## üìà Resultados Esperados

### Dados Tabulares

#### Regress√£o Log√≠stica

- **Accuracy**: ~96.5%
- **Precision (M)**: ~97.7%
- **Recall (M)**: ~92.9%
- **F1-Score (M)**: ~95.2%

#### Random Forest (Melhor Modelo)

- **Accuracy**: ~97.4%
- **Precision (M)**: ~100.0%
- **Recall (M)**: ~92.9%
- **F1-Score (M)**: ~96.3%

### Classifica√ß√£o de Imagens (CNNs)

#### Pneumonia em Raio-X

- **Modelo**: CNN constru√≠da do zero
- **Arquitetura**: 4 blocos convolucionais + camadas densas
- **Input**: Imagens RGB 224x224
- **M√©tricas Esperadas**: Accuracy > 80% (benchmark para CNNs simples)

#### C√¢ncer de Mama em Mamografias

- **Modelo**: CNN adaptada para escala de cinza
- **Arquitetura**: 5 blocos convolucionais + camadas densas
- **Input**: Imagens em escala de cinza 256x256
- **M√©tricas Esperadas**: Accuracy > 80%

### Features Mais Importantes (Dados Tabulares)

As caracter√≠sticas mais preditivas identificadas:

1. `concave points_worst` - Pontos c√¥ncavos (pior valor)
2. `perimeter_worst` - Per√≠metro (pior valor)
3. `concave points_mean` - Pontos c√¥ncavos (m√©dia)
4. `radius_worst` - Raio (pior valor)
5. `area_worst` - √Årea (pior valor)

---

## üîç Interpretabilidade

### Dados Tabulares

1. **Feature Importance**: Import√¢ncia global das features (Random Forest)
2. **SHAP Values**:
   - Interpretabilidade local (por predi√ß√£o)
   - Interpretabilidade global (vis√£o geral)
   - Waterfall plots para casos espec√≠ficos

### Classifica√ß√£o de Imagens

1. **Grad-CAM**: Visualiza√ß√£o das regi√µes da imagem que mais influenciam a predi√ß√£o
   - Heatmaps sobrepostos nas imagens
   - An√°lise de casos corretos e incorretos
   - Identifica√ß√£o de padr√µes aprendidos pelo modelo

---

## ‚ö†Ô∏è Limita√ß√µes e Considera√ß√µes

### Limita√ß√µes T√©cnicas

- Dataset limitado (~570 amostras)
- Apenas caracter√≠sticas num√©ricas de exames
- N√£o considera hist√≥rico m√©dico completo
- Poss√≠vel vi√©s geogr√°fico/temporal

### Considera√ß√µes para Uso Cl√≠nico

- **N√ÉO substitui o diagn√≥stico m√©dico**
- Requer valida√ß√£o cl√≠nica extensiva
- Necessita aprova√ß√£o regulat√≥ria
- Monitoramento cont√≠nuo essencial
- Transpar√™ncia e responsabilidade √©tica

Para mais detalhes, consulte a se√ß√£o de **Discuss√£o Cr√≠tica** no notebook `02_tabular_modelagem.ipynb` e o `relatorio_tecnico.md`.

---

## üê≥ Docker (Opcional)

Para executar em container Docker:

```bash
# Construir imagem
docker build -t tech-challenge .

# Executar container
docker run -it -p 8888:8888 tech-challenge
```

---

## üìö Documenta√ß√£o Adicional

- **Relat√≥rio T√©cnico**: `relatorio_tecnico.md` - Documenta√ß√£o completa do projeto
- **Notebooks**: Cont√™m an√°lise detalhada e coment√°rios explicativos
- **C√≥digo Fonte**: Fun√ß√µes modulares em `src/tabular/` e `src/vision/`

---

## üë• Contribui√ß√£o

Este projeto foi desenvolvido como parte do Tech Challenge Fase 1.

---

## üìÑ Licen√ßa

Consulte o arquivo `LICENSE` para mais informa√ß√µes.

---

## üìû Contato

Para d√∫vidas ou sugest√µes, abra uma issue no reposit√≥rio.
