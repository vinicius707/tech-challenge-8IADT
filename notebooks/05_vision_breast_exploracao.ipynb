{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análise Exploratória - Câncer de Mama (CBIS-DDSM)\n",
        "\n",
        "Este notebook realiza uma análise exploratória do dataset de câncer de mama (CBIS-DDSM), focando em:\n",
        "\n",
        "- Download do dataset do Kaggle\n",
        "- Análise da estrutura de diretórios\n",
        "- Estatísticas descritivas (número de imagens por classe)\n",
        "- Visualização de amostras de imagens\n",
        "- Análise de distribuição de classes\n",
        "- Verificação de dimensões das imagens\n",
        "- Análise de qualidade das imagens\n",
        "\n",
        "## Dataset\n",
        "\n",
        "O dataset utilizado é o **CBIS-DDSM (Curated Breast Imaging Subset of DDSM)** do Kaggle, que contém imagens de mamografia classificadas em:\n",
        "- **Benigno**: Lesões benignas\n",
        "- **Maligno**: Lesões malignas (câncer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "from PIL import Image\n",
        "\n",
        "# Adicionar o diretório raiz do projeto ao sys.path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Importar módulos do projeto\n",
        "from src.vision.data_loader import (\n",
        "    download_breast_cancer_dataset,\n",
        "    load_image_dataset,\n",
        "    get_class_distribution,\n",
        "    validate_images,\n",
        "    get_image_info\n",
        ")\n",
        "\n",
        "# Configuração\n",
        "with open(\"../config.yaml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Módulos importados com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Download do Dataset\n",
        "\n",
        "Primeiro, vamos baixar o dataset do Kaggle usando kagglehub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baixar dataset de câncer de mama\n",
        "dataset_path = download_breast_cancer_dataset(\n",
        "    target_path=config[\"data\"][\"images\"][\"breast_cancer_path\"]\n",
        ")\n",
        "\n",
        "print(f\"\\nDataset disponível em: {dataset_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carregamento e Estrutura do Dataset\n",
        "\n",
        "Vamos carregar as imagens e analisar a estrutura do dataset. O CBIS-DDSM pode ter uma estrutura mais complexa que o dataset de pneumonia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar dataset\n",
        "# O CBIS-DDSM pode ter estrutura diferente, vamos tentar carregar\n",
        "df = load_image_dataset(dataset_path)\n",
        "\n",
        "print(f\"Total de imagens carregadas: {len(df)}\")\n",
        "print(f\"\\nPrimeiras linhas do DataFrame:\")\n",
        "print(df.head(10))\n",
        "\n",
        "print(f\"\\nEstrutura do dataset:\")\n",
        "print(df.info())\n",
        "\n",
        "# Verificar estrutura de diretórios\n",
        "print(f\"\\nEstrutura de diretórios explorada:\")\n",
        "if 'split' in df.columns:\n",
        "    print(f\"Splits encontrados: {df['split'].unique()}\")\n",
        "print(f\"Classes encontradas: {df['label'].unique()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Análise da Distribuição de Classes\n",
        "\n",
        "Vamos analisar a distribuição das classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribuição de classes\n",
        "distribution = get_class_distribution(df, split_col='split' if 'split' in df.columns else None)\n",
        "\n",
        "print(\"Distribuição de Classes:\")\n",
        "print(\"=\" * 60)\n",
        "print(distribution)\n",
        "\n",
        "# Visualização\n",
        "if 'split' in df.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Gráfico de barras por split\n",
        "    split_dist = pd.crosstab(df['split'], df['label'])\n",
        "    split_dist.plot(kind='bar', ax=axes[0], stacked=False)\n",
        "    axes[0].set_title('Distribuição de Classes por Split', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Split')\n",
        "    axes[0].set_ylabel('Número de Imagens')\n",
        "    axes[0].legend(title='Classe')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Gráfico de pizza geral\n",
        "    label_counts = df['label'].value_counts()\n",
        "    axes[1].pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "    axes[1].set_title('Distribuição Geral de Classes', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    # Se não houver split, apenas mostrar distribuição geral\n",
        "    label_counts = df['label'].value_counts()\n",
        "    print(\"\\nDistribuição Geral:\")\n",
        "    print(label_counts)\n",
        "    \n",
        "    plt.figure(figsize=(8, 5))\n",
        "    label_counts.plot(kind='bar')\n",
        "    plt.title('Distribuição de Classes', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Classe')\n",
        "    plt.ylabel('Número de Imagens')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualização de Amostras\n",
        "\n",
        "Vamos visualizar algumas amostras de imagens de cada classe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar amostras de cada classe\n",
        "classes = df['label'].unique()\n",
        "num_samples_per_class = 4\n",
        "\n",
        "fig, axes = plt.subplots(len(classes), num_samples_per_class, figsize=(16, 8))\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_images = df[df['label'] == class_name].sample(num_samples_per_class, random_state=42)\n",
        "    \n",
        "    for j, (idx, row) in enumerate(class_images.iterrows()):\n",
        "        try:\n",
        "            img = Image.open(row['image_path'])\n",
        "            # Mamografias geralmente são em escala de cinza\n",
        "            axes[i, j].imshow(img, cmap='gray')\n",
        "            axes[i, j].set_title(f'{class_name}\\n{Path(row[\"image_path\"]).name}', fontsize=10)\n",
        "            axes[i, j].axis('off')\n",
        "        except Exception as e:\n",
        "            axes[i, j].text(0.5, 0.5, f'Erro:\\n{str(e)}', \n",
        "                          ha='center', va='center', transform=axes[i, j].transAxes)\n",
        "            axes[i, j].axis('off')\n",
        "\n",
        "plt.suptitle('Amostras de Imagens por Classe', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Análise de Dimensões e Qualidade das Imagens\n",
        "\n",
        "Vamos analisar as dimensões das imagens e verificar sua qualidade.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obter informações sobre as imagens\n",
        "image_info = get_image_info(df, sample_size=min(500, len(df)))\n",
        "\n",
        "print(\"Informações sobre as Imagens:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total de imagens: {image_info['total_images']}\")\n",
        "print(f\"\\nDimensões médias (amostra de {min(500, len(df))} imagens):\")\n",
        "print(f\"  Largura média: {image_info['width_mean']:.1f} ± {image_info['width_std']:.1f} pixels\")\n",
        "print(f\"  Altura média: {image_info['height_mean']:.1f} ± {image_info['height_std']:.1f} pixels\")\n",
        "print(f\"\\nFormatos de arquivo:\")\n",
        "for fmt, count in image_info['formats'].items():\n",
        "    print(f\"  {fmt}: {count} imagens\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Validação de Imagens\n",
        "\n",
        "Vamos validar as imagens e remover arquivos corrompidos, se houver.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validar imagens (isso pode levar algum tempo)\n",
        "print(f\"Validando {len(df)} imagens...\")\n",
        "df_valid = validate_images(df)\n",
        "\n",
        "print(f\"\\nImagens válidas: {len(df_valid)}\")\n",
        "print(f\"Imagens removidas: {len(df) - len(df_valid)}\")\n",
        "\n",
        "# Atualizar DataFrame\n",
        "df = df_valid.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Resumo e Próximos Passos\n",
        "\n",
        "### Resumo da Análise Exploratória\n",
        "\n",
        "- **Total de imagens**: {len(df)}\n",
        "- **Classes**: {', '.join(df['label'].unique())}\n",
        "- **Distribuição**: {df['label'].value_counts().to_dict()}\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "1. Pré-processamento das imagens (redimensionamento, normalização, conversão para escala de cinza)\n",
        "2. Divisão dos dados em treino/validação/teste\n",
        "3. Treinamento de modelos CNN\n",
        "4. Avaliação e interpretabilidade\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
