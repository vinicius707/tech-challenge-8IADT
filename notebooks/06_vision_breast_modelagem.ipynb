{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelagem de CNN - Câncer de Mama (CBIS-DDSM)\n",
        "\n",
        "Este notebook implementa e treina modelos de Redes Neurais Convolucionais (CNNs) para classificação de câncer de mama em imagens de mamografia.\n",
        "\n",
        "## Metodologia\n",
        "\n",
        "- **Pré-processamento**: Redimensionamento, normalização, conversão para escala de cinza, data augmentation\n",
        "- **Divisão dos Dados**: 60% treino / 20% validação / 20% teste\n",
        "- **Modelos**: CNN construída do zero (adaptada para imagens em escala de cinza)\n",
        "- **Avaliação**: Accuracy, Precision, Recall, F1-Score, ROC-AUC\n",
        "- **Interpretabilidade**: Grad-CAM para visualizar regiões importantes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Adicionar o diretório raiz do projeto ao sys.path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Importar módulos do projeto\n",
        "from src.vision.data_loader import load_image_dataset\n",
        "from src.vision.preprocessing import split_image_data, create_data_generators\n",
        "from src.vision.models import (\n",
        "    create_cnn_breast_cancer,\n",
        "    compile_model,\n",
        "    get_model_callbacks\n",
        ")\n",
        "from src.vision.evaluation import (\n",
        "    plot_training_history,\n",
        "    plot_confusion_matrix,\n",
        "    plot_roc_curve,\n",
        "    visualize_predictions,\n",
        "    plot_grad_cam,\n",
        "    evaluate_model\n",
        ")\n",
        "\n",
        "# Configuração\n",
        "with open(\"../config.yaml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Configurações do TensorFlow\n",
        "tf.random.set_seed(config[\"split\"][\"random_state\"])\n",
        "np.random.seed(config[\"split\"][\"random_state\"])\n",
        "\n",
        "print(\"Módulos importados com sucesso!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Preparação dos Dados\n",
        "\n",
        "Carregamos o dataset e dividimos em conjuntos de treino, validação e teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar dataset\n",
        "dataset_path = config[\"data\"][\"images\"][\"breast_cancer_path\"]\n",
        "\n",
        "# Carregar imagens\n",
        "df = load_image_dataset(dataset_path)\n",
        "\n",
        "print(f\"Total de imagens: {len(df)}\")\n",
        "print(f\"Classes: {df['label'].unique()}\")\n",
        "\n",
        "# Criar split (mamografias geralmente não vêm pré-divididas)\n",
        "train_df, val_df, test_df = split_image_data(\n",
        "    df,\n",
        "    test_size=config[\"split\"][\"test_size\"],\n",
        "    validation_size=config[\"split\"][\"validation_size\"],\n",
        "    random_state=config[\"split\"][\"random_state\"]\n",
        ")\n",
        "\n",
        "print(f\"\\nDivisão dos dados:\")\n",
        "print(f\"  Treino:    {len(train_df)} amostras ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"  Validação: {len(val_df)} amostras ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"  Teste:     {len(test_df)} amostras ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nDistribuição das classes no treino:\")\n",
        "print(train_df['label'].value_counts())\n",
        "print(f\"\\nDistribuição das classes na validação:\")\n",
        "print(val_df['label'].value_counts())\n",
        "print(f\"\\nDistribuição das classes no teste:\")\n",
        "print(test_df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Criar Data Generators\n",
        "\n",
        "Criamos generators para treino, validação e teste. Mamografias são geralmente em escala de cinza.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurações\n",
        "image_size = tuple(config[\"models\"][\"cnn\"][\"image_size\"][\"breast_cancer\"])\n",
        "batch_size = config[\"models\"][\"cnn\"][\"batch_size\"]\n",
        "\n",
        "# Criar data generators (mamografias em escala de cinza)\n",
        "train_gen, val_gen, test_gen = create_data_generators(\n",
        "    train_df=train_df,\n",
        "    val_df=val_df,\n",
        "    test_df=test_df,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    color_mode='grayscale',  # Mamografias são em escala de cinza\n",
        "    class_mode='categorical',\n",
        "    augmentation=True\n",
        ")\n",
        "\n",
        "# Obter nomes das classes\n",
        "class_names = list(train_gen.class_indices.keys())\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"Índices das classes: {train_gen.class_indices}\")\n",
        "\n",
        "print(f\"\\nTamanho dos generators:\")\n",
        "print(f\"  Treino:    {len(train_gen)} batches\")\n",
        "print(f\"  Validação: {len(val_gen)} batches\")\n",
        "print(f\"  Teste:     {len(test_gen)} batches\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Modelo: CNN para Câncer de Mama\n",
        "\n",
        "Vamos criar e treinar uma CNN adaptada para imagens de mamografia em escala de cinza.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar modelo (escala de cinza: 1 canal)\n",
        "input_shape = (*image_size, 1)  # Grayscale\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = create_cnn_breast_cancer(\n",
        "    input_shape=input_shape,\n",
        "    num_classes=num_classes,\n",
        "    dropout_rate=0.5\n",
        ")\n",
        "\n",
        "# Compilar modelo\n",
        "learning_rate = config[\"models\"][\"cnn\"][\"learning_rate\"]\n",
        "model = compile_model(model, learning_rate=learning_rate)\n",
        "\n",
        "# Resumo do modelo\n",
        "print(\"Arquitetura do Modelo:\")\n",
        "print(\"=\" * 60)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Treinamento do Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurações de treinamento\n",
        "epochs = config[\"models\"][\"cnn\"][\"epochs\"]\n",
        "patience = config[\"models\"][\"cnn\"][\"early_stopping_patience\"]\n",
        "\n",
        "# Criar callbacks\n",
        "checkpoint_path = \"../models/breast_cancer_cnn_model.h5\"\n",
        "callbacks = get_model_callbacks(\n",
        "    checkpoint_path=checkpoint_path,\n",
        "    patience=patience,\n",
        "    monitor='val_loss'\n",
        ")\n",
        "\n",
        "# Treinar modelo\n",
        "print(\"Iniciando treinamento...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTreinamento concluído!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Visualização do Histórico de Treinamento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar histórico de treinamento\n",
        "plot_training_history(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Avaliação do Modelo\n",
        "\n",
        "Avaliamos o modelo no conjunto de teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar melhor modelo (salvo pelo ModelCheckpoint)\n",
        "best_model = keras.models.load_model(checkpoint_path)\n",
        "\n",
        "# Avaliar modelo\n",
        "print(\"Avaliação no Conjunto de Teste:\")\n",
        "print(\"=\" * 60)\n",
        "metrics = evaluate_model(best_model, test_gen, class_names, verbose=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Matriz de Confusão\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obter predições para matriz de confusão\n",
        "y_pred_proba = best_model.predict(test_gen, verbose=0)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "# Obter labels verdadeiros\n",
        "y_true = []\n",
        "for i in range(len(test_gen)):\n",
        "    _, y_batch = test_gen[i]\n",
        "    y_true.extend(np.argmax(y_batch, axis=1))\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Plotar matriz de confusão\n",
        "plot_confusion_matrix(y_true, y_pred, class_names, normalize=False)\n",
        "plot_confusion_matrix(y_true, y_pred, class_names, normalize=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Curva ROC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotar curva ROC\n",
        "y_true_onehot = keras.utils.to_categorical(y_true, len(class_names))\n",
        "plot_roc_curve(y_true_onehot, y_pred_proba, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Visualização de Predições\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar predições\n",
        "visualize_predictions(best_model, test_gen, class_names, num_samples=16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Interpretabilidade com Grad-CAM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selecionar algumas amostras para análise Grad-CAM\n",
        "x_batch, y_batch = test_gen[0]\n",
        "\n",
        "# Selecionar amostras de cada classe\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    class_samples = np.where(np.argmax(y_batch, axis=1) == class_idx)[0]\n",
        "    if len(class_samples) > 0:\n",
        "        sample_idx = class_samples[0]\n",
        "        img_array = x_batch[sample_idx]\n",
        "        \n",
        "        print(f\"\\nGrad-CAM para amostra de classe '{class_name}':\")\n",
        "        plot_grad_cam(best_model, img_array, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Persistência do Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar se o modelo foi salvo\n",
        "import os\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"Modelo salvo com sucesso em: {checkpoint_path}\")\n",
        "    \n",
        "    # Carregar e validar modelo salvo\n",
        "    loaded_model = keras.models.load_model(checkpoint_path)\n",
        "    \n",
        "    # Fazer uma predição de teste\n",
        "    test_batch_x, test_batch_y = test_gen[0]\n",
        "    test_pred = loaded_model.predict(test_batch_x[:1], verbose=0)\n",
        "    test_true = np.argmax(test_batch_y[0])\n",
        "    test_pred_class = np.argmax(test_pred[0])\n",
        "    \n",
        "    print(f\"\\nValidação do modelo carregado:\")\n",
        "    print(f\"  Imagem de teste - Classe verdadeira: {class_names[test_true]}\")\n",
        "    print(f\"  Predição: {class_names[test_pred_class]} (confiança: {test_pred[0][test_pred_class]*100:.2f}%)\")\n",
        "    print(\"\\nModelo validado com sucesso!\")\n",
        "else:\n",
        "    print(f\"Modelo não encontrado em: {checkpoint_path}\")\n",
        "    print(\"Salvando modelo manualmente...\")\n",
        "    best_model.save(checkpoint_path)\n",
        "    print(\"Modelo salvo!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
