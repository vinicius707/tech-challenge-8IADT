{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelagem de CNN - Pneumonia em Raio-X\n",
        "\n",
        "Este notebook implementa e treina modelos de Redes Neurais Convolucionais (CNNs) para classificação de pneumonia em imagens de raio-X de tórax.\n",
        "\n",
        "## Metodologia\n",
        "\n",
        "- **Pré-processamento**: Redimensionamento, normalização, data augmentation\n",
        "- **Divisão dos Dados**: 60% treino / 20% validação / 20% teste\n",
        "- **Modelos**: CNN construída do zero\n",
        "- **Avaliação**: Accuracy, Precision, Recall, F1-Score, ROC-AUC\n",
        "- **Interpretabilidade**: Grad-CAM para visualizar regiões importantes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Adicionar o diretório raiz do projeto ao sys.path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Importar módulos do projeto\n",
        "from src.vision.data_loader import load_image_dataset\n",
        "from src.vision.preprocessing import split_image_data, create_data_generators\n",
        "from src.vision.models import (\n",
        "    create_simple_cnn_pneumonia,\n",
        "    compile_model,\n",
        "    get_model_callbacks\n",
        ")\n",
        "from src.vision.evaluation import (\n",
        "    plot_training_history,\n",
        "    plot_confusion_matrix,\n",
        "    plot_roc_curve,\n",
        "    visualize_predictions,\n",
        "    plot_grad_cam,\n",
        "    evaluate_model\n",
        ")\n",
        "\n",
        "# Configuração\n",
        "with open(\"../config.yaml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Configurações do TensorFlow\n",
        "tf.random.set_seed(config[\"split\"][\"random_state\"])\n",
        "np.random.seed(config[\"split\"][\"random_state\"])\n",
        "\n",
        "print(\"Módulos importados com sucesso!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Preparação dos Dados\n",
        "\n",
        "Carregamos o dataset e dividimos em conjuntos de treino, validação e teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar dataset\n",
        "# Assumindo que o dataset já foi baixado no notebook de exploração\n",
        "# Se não, descomente a linha abaixo:\n",
        "# from src.vision.data_loader import download_pneumonia_dataset\n",
        "# dataset_path = download_pneumonia_dataset(config[\"data\"][\"images\"][\"pneumonia_path\"])\n",
        "\n",
        "# Para este exemplo, vamos assumir que temos o path do dataset\n",
        "# Em produção, você pode salvar o path do notebook de exploração\n",
        "dataset_path = config[\"data\"][\"images\"][\"pneumonia_path\"]\n",
        "\n",
        "# Carregar imagens\n",
        "df = load_image_dataset(dataset_path)\n",
        "\n",
        "print(f\"Total de imagens: {len(df)}\")\n",
        "print(f\"Classes: {df['label'].unique()}\")\n",
        "\n",
        "# Se o dataset já tem split (train/test), vamos usar\n",
        "# Caso contrário, vamos criar nosso próprio split\n",
        "if 'split' in df.columns and 'train' in df['split'].values:\n",
        "    # Usar split existente\n",
        "    train_df = df[df['split'] == 'train'].copy()\n",
        "    test_df = df[df['split'] == 'test'].copy() if 'test' in df['split'].values else None\n",
        "    \n",
        "    # Se não houver validação, criar a partir do treino\n",
        "    if 'val' in df['split'].values or 'validation' in df['split'].values:\n",
        "        val_df = df[df['split'].isin(['val', 'validation'])].copy()\n",
        "    else:\n",
        "        train_df, val_df, _ = split_image_data(\n",
        "            train_df,\n",
        "            test_size=0.2,\n",
        "            validation_size=0.2,\n",
        "            random_state=config[\"split\"][\"random_state\"]\n",
        "        )\n",
        "    \n",
        "    if test_df is None:\n",
        "        # Criar teste a partir do treino se não existir\n",
        "        train_df, _, test_df = split_image_data(\n",
        "            train_df,\n",
        "            test_size=0.2,\n",
        "            validation_size=0.0,\n",
        "            random_state=config[\"split\"][\"random_state\"]\n",
        "        )\n",
        "else:\n",
        "    # Criar split do zero\n",
        "    train_df, val_df, test_df = split_image_data(\n",
        "        df,\n",
        "        test_size=config[\"split\"][\"test_size\"],\n",
        "        validation_size=config[\"split\"][\"validation_size\"],\n",
        "        random_state=config[\"split\"][\"random_state\"]\n",
        "    )\n",
        "\n",
        "print(f\"\\nDivisão dos dados:\")\n",
        "print(f\"  Treino:    {len(train_df)} amostras ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"  Validação: {len(val_df)} amostras ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"  Teste:     {len(test_df)} amostras ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nDistribuição das classes no treino:\")\n",
        "print(train_df['label'].value_counts())\n",
        "print(f\"\\nDistribuição das classes na validação:\")\n",
        "print(val_df['label'].value_counts())\n",
        "print(f\"\\nDistribuição das classes no teste:\")\n",
        "print(test_df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Criar Data Generators\n",
        "\n",
        "Criamos generators para treino, validação e teste com data augmentation para o conjunto de treino.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurações\n",
        "image_size = tuple(config[\"models\"][\"cnn\"][\"image_size\"][\"pneumonia\"])\n",
        "batch_size = config[\"models\"][\"cnn\"][\"batch_size\"]\n",
        "\n",
        "# Criar data generators\n",
        "train_gen, val_gen, test_gen = create_data_generators(\n",
        "    train_df=train_df,\n",
        "    val_df=val_df,\n",
        "    test_df=test_df,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    augmentation=True\n",
        ")\n",
        "\n",
        "# Obter nomes das classes\n",
        "class_names = list(train_gen.class_indices.keys())\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"Índices das classes: {train_gen.class_indices}\")\n",
        "\n",
        "print(f\"\\nTamanho dos generators:\")\n",
        "print(f\"  Treino:    {len(train_gen)} batches\")\n",
        "print(f\"  Validação: {len(val_gen)} batches\")\n",
        "print(f\"  Teste:     {len(test_gen)} batches\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Modelo: CNN Simples\n",
        "\n",
        "Vamos criar e treinar uma CNN construída do zero.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar modelo\n",
        "input_shape = (*image_size, 3)  # RGB\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = create_simple_cnn_pneumonia(\n",
        "    input_shape=input_shape,\n",
        "    num_classes=num_classes,\n",
        "    dropout_rate=0.5\n",
        ")\n",
        "\n",
        "# Compilar modelo\n",
        "learning_rate = config[\"models\"][\"cnn\"][\"learning_rate\"]\n",
        "model = compile_model(model, learning_rate=learning_rate)\n",
        "\n",
        "# Resumo do modelo\n",
        "print(\"Arquitetura do Modelo:\")\n",
        "print(\"=\" * 60)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Treinamento do Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurações de treinamento\n",
        "epochs = config[\"models\"][\"cnn\"][\"epochs\"]\n",
        "patience = config[\"models\"][\"cnn\"][\"early_stopping_patience\"]\n",
        "\n",
        "# Criar callbacks\n",
        "checkpoint_path = \"../models/pneumonia_cnn_model.h5\"\n",
        "callbacks = get_model_callbacks(\n",
        "    checkpoint_path=checkpoint_path,\n",
        "    patience=patience,\n",
        "    monitor='val_loss'\n",
        ")\n",
        "\n",
        "# Treinar modelo\n",
        "print(\"Iniciando treinamento...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTreinamento concluído!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Visualização do Histórico de Treinamento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar histórico de treinamento\n",
        "plot_training_history(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Avaliação do Modelo\n",
        "\n",
        "Avaliamos o modelo no conjunto de teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar melhor modelo (salvo pelo ModelCheckpoint)\n",
        "best_model = keras.models.load_model(checkpoint_path)\n",
        "\n",
        "# Avaliar modelo\n",
        "print(\"Avaliação no Conjunto de Teste:\")\n",
        "print(\"=\" * 60)\n",
        "metrics = evaluate_model(best_model, test_gen, class_names, verbose=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Matriz de Confusão\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obter predições para matriz de confusão\n",
        "y_pred_proba = best_model.predict(test_gen, verbose=0)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "# Obter labels verdadeiros\n",
        "y_true = []\n",
        "for i in range(len(test_gen)):\n",
        "    _, y_batch = test_gen[i]\n",
        "    y_true.extend(np.argmax(y_batch, axis=1))\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Plotar matriz de confusão\n",
        "plot_confusion_matrix(y_true, y_pred, class_names, normalize=False)\n",
        "plot_confusion_matrix(y_true, y_pred, class_names, normalize=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Curva ROC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotar curva ROC\n",
        "y_true_onehot = keras.utils.to_categorical(y_true, len(class_names))\n",
        "plot_roc_curve(y_true_onehot, y_pred_proba, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Visualização de Predições\n",
        "\n",
        "Visualizamos algumas predições corretas e incorretas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar predições\n",
        "visualize_predictions(best_model, test_gen, class_names, num_samples=16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Interpretabilidade com Grad-CAM\n",
        "\n",
        "Usamos Grad-CAM para visualizar as regiões da imagem que mais influenciam a predição do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selecionar algumas amostras para análise Grad-CAM\n",
        "num_gradcam_samples = 4\n",
        "\n",
        "# Obter batch do test generator\n",
        "x_batch, y_batch = test_gen[0]\n",
        "\n",
        "# Selecionar amostras de cada classe\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    class_samples = np.where(np.argmax(y_batch, axis=1) == class_idx)[0]\n",
        "    if len(class_samples) > 0:\n",
        "        sample_idx = class_samples[0]\n",
        "        img_array = x_batch[sample_idx]\n",
        "        \n",
        "        print(f\"\\nGrad-CAM para amostra de classe '{class_name}':\")\n",
        "        plot_grad_cam(best_model, img_array, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Persistência do Modelo\n",
        "\n",
        "O modelo já foi salvo automaticamente durante o treinamento pelo ModelCheckpoint. Vamos verificar e fazer uma validação final.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar se o modelo foi salvo\n",
        "import os\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"Modelo salvo com sucesso em: {checkpoint_path}\")\n",
        "    \n",
        "    # Carregar e validar modelo salvo\n",
        "    loaded_model = keras.models.load_model(checkpoint_path)\n",
        "    \n",
        "    # Fazer uma predição de teste\n",
        "    test_batch_x, test_batch_y = test_gen[0]\n",
        "    test_pred = loaded_model.predict(test_batch_x[:1], verbose=0)\n",
        "    test_true = np.argmax(test_batch_y[0])\n",
        "    test_pred_class = np.argmax(test_pred[0])\n",
        "    \n",
        "    print(f\"\\nValidação do modelo carregado:\")\n",
        "    print(f\"  Imagem de teste - Classe verdadeira: {class_names[test_true]}\")\n",
        "    print(f\"  Predição: {class_names[test_pred_class]} (confiança: {test_pred[0][test_pred_class]*100:.2f}%)\")\n",
        "    print(\"\\nModelo validado com sucesso!\")\n",
        "else:\n",
        "    print(f\"Modelo não encontrado em: {checkpoint_path}\")\n",
        "    print(\"Salvando modelo manualmente...\")\n",
        "    best_model.save(checkpoint_path)\n",
        "    print(\"Modelo salvo!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
